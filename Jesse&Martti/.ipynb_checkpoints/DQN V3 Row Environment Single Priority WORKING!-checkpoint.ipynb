{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e30ba6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "#from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efaa9bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu 1\n"
     ]
    }
   ],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "156e0f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[ 4  5  4  5  6  7  3]\n",
      " [ 5  7  3  3  4  5  3]\n",
      " [ 6  7  7  5  5  5 10]\n",
      " [ 4  5  5  6  8  4  3]\n",
      " [ 6  1  6  6  2  4  6]]\n"
     ]
    }
   ],
   "source": [
    "rowcount = 7\n",
    "testenv = np.random.randint(0,5,(rowcount,5,5))\n",
    "priorityCount = max(testenv.flatten())\n",
    "print(priorityCount)\n",
    "outputlist = np.zeros((priorityCount+1,rowcount),dtype=int)\n",
    "\n",
    "for i in range(priorityCount+1):\n",
    "    outputlist[i] = (testenv == i).sum(axis=2).sum(axis=1)\n",
    "print(outputlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8772bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: een keuze tussen bij 4 keuzes (bij 4x?x?)\n",
    "#Output: Nieuwe environment\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, size, posreward = 2, negreward = -2, maxPriority = 4):\n",
    "        self.size = size\n",
    "        self.environment = np.array([[[0] * self.size[2]] * self.size[1]] * self.size[0])\n",
    "        self.posreward = posreward\n",
    "        self.negreward = negreward\n",
    "        self.action_space = self.environment.shape[0]\n",
    "        self.observation_space = np.prod(size)\n",
    "        self.input_space = size[0]*(maxPriority)\n",
    "        self.priorityMax = maxPriority\n",
    "        \n",
    "    def resetField(self):\n",
    "        self.environment = np.array([[[0] * self.size[2]] * self.size[1]] * self.size[0])\n",
    "        \n",
    "    def resetEnvironment(self):\n",
    "        self.resetField()\n",
    "        self.score = 0\n",
    "        self.done = False\n",
    "    \n",
    "    def GenerateEnvironment(self):\n",
    "        return np.array([[[0] * self.size[2]] * self.size[1]] * self.size[0])\n",
    "        temp = np.array([[[0] * self.size[2]] * self.size[1]] * self.size[0])\n",
    "        maxcont = self.size[0] * self.size[2]\n",
    "        for i in range(self.size[1]):\n",
    "            for o in range(np.random.randint(maxcont*0.65,maxcont)):\n",
    "                actionPos = self.checkValidPositionInRow(temp,i)\n",
    "                temp[actionPos] = 1\n",
    "        return temp\n",
    "    \n",
    "    def genObs(self, env, flattened=True):\n",
    "        #Count amount of open containers per row.\n",
    "        outputlist = np.zeros((self.priorityMax,self.size[0]),dtype=np.float32)\n",
    "\n",
    "        for i in range(self.priorityMax):\n",
    "            outputlist[i] = (env == i).sum(axis=2).sum(axis=1)\n",
    "            \n",
    "        if flattened:\n",
    "            return outputlist.flatten()\n",
    "        else:\n",
    "            return outputlist\n",
    "        \n",
    "        \n",
    "        #return np.array((env == 0).sum(axis=2).sum(axis=1), dtype=np.float32)\n",
    "        #return np.array((env == 0).sum(axis=2), dtype=np.float32)\n",
    "    \n",
    "    def step(self, env, action, priority = 1):\n",
    "        #actionspace = y\n",
    "        \n",
    "        \n",
    "        #Save Old State\n",
    "        newState = env.copy()\n",
    "        actionPos = self.checkValidPositionInRow(env, action)\n",
    "        \n",
    "        done = False\n",
    "        \n",
    "        #Make move\n",
    "        if self.placeContainer(actionPos, newState):\n",
    "            newState[actionPos] = priority\n",
    "            reward = self.getRewardList(env, priority)[action]\n",
    "        else:\n",
    "            reward = -2\n",
    "            done = True\n",
    "            self.done = True\n",
    "        \n",
    "        \n",
    "        #reward = self.getRewardList(env, priority)[action]\n",
    "        \n",
    "        #End game if field is all #s or if the user messed up.\n",
    "        if np.all(newState != 0):\n",
    "            done = True\n",
    "            self.done = True\n",
    "        return newState, reward, done\n",
    "    \n",
    "    def placeContainer(self, pos, env):\n",
    "        if self.isLegal(pos, env):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def isLegal(self, pos, env):\n",
    "        IO = self.isOccupied(pos, env)\n",
    "        IF = self.isFloating(pos, env)\n",
    "        IIE = self.posIsInEnv(pos, env)\n",
    "        NAS = self.hasNorthAndSouth(pos, env)\n",
    "        #print(IO,IF,IIE,NAS)\n",
    "        return not IO and not IF and IIE and not NAS\n",
    "    \n",
    "    def isOccupied(self, pos, env):\n",
    "        if self.posIsInEnv(pos, env):\n",
    "            return env[pos] != 0\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def hasNorthAndSouth(self, pos, env):\n",
    "        NC = self.isOccupied((pos[0],pos[1]-1,0), env)\n",
    "        SC = self.isOccupied((pos[0],pos[1]+1,0), env)\n",
    "        #print(NC,SC)\n",
    "        return NC and SC\n",
    "    \n",
    "    def posIsInEnv(self, pos, env):\n",
    "        x = 0 <= pos[0] < env.shape[0]\n",
    "        y = 0 <= pos[1] < env.shape[1]\n",
    "        z = 0 <= pos[2] < env.shape[2]  \n",
    "        return x and y and z\n",
    "    \n",
    "    def isFloating(self, pos, env):\n",
    "        return np.any(env[pos[0],pos[1],:pos[2]] == 0)\n",
    "    \n",
    "    def checkValidPositionInRow(self, env, row):\n",
    "        positions = np.dstack(np.where(env[row,:,:] == 0))\n",
    "        if positions.size != 0:\n",
    "            result = positions[positions[:,:,0] == np.max(positions[:,:,0])][0]\n",
    "            \n",
    "        else:\n",
    "            result = (0,0)\n",
    "        return row, result[0], result[1]\n",
    "    \n",
    "    def getRewardList(self,env,containerPriority):\n",
    "        obs = self.genObs(env,flattened=False)\n",
    "        multarr = np.full(obs.shape, -1)\n",
    "        multarr[containerPriority] *= -1\n",
    "        multarr[0] *= 0\n",
    "        obs *= multarr\n",
    "        \n",
    "        return obs.sum(axis=0)\n",
    "        #print(obs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #OLDCODE\n",
    "        #Set to 0 if there are priority containers below\n",
    "        obs[0] *= obs[1:,:].sum(axis=0) == 0\n",
    "\n",
    "        #Generate array with only -1\n",
    "        multarr = np.full(obs.shape, -1)\n",
    "\n",
    "        #Invert for current container priority\n",
    "        multarr[containerPriority] *= -1\n",
    "\n",
    "        #Apply multiplier array\n",
    "        obs *= multarr\n",
    "\n",
    "        #Change empty spaces to 0.5 if there's no other containers there.\n",
    "        #obs[0] = (obs[0] <0)*0.5\n",
    "        \n",
    "        #If row is full, don't reward\n",
    "        obs *= (obs != np.prod(self.size[1:3]))\n",
    "        \n",
    "        obs = np.clip(obs,-1,3)\n",
    "        \n",
    "        #Get reward for move.\n",
    "        #print(obs.sum(axis=0))\n",
    "        return obs.sum(axis=0)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7744ffb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.,  20.,   0., -25.,   0.], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reward: When putting same type containers \n",
    "\n",
    "env = Environment(size=(5,5,5))\n",
    "\n",
    "testenv = np.empty((5,5,5))\n",
    "testenv[0,0,0] = 1\n",
    "testenv[0,1,0] = 1\n",
    "testenv[0,2,0] = 1\n",
    "\n",
    "testenv[1,:,:-1] = 3\n",
    "testenv[3,:,:] = 2\n",
    "containerpriority = 3\n",
    "action = 1\n",
    "\n",
    "\n",
    "env.getRewardList(testenv,containerpriority)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1578bbf9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 6. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 12\n",
      "[6. 6. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 12\n"
     ]
    }
   ],
   "source": [
    "#UnitTests\n",
    "for o in range(2):\n",
    "    e = Environment(size=(3,3,2))\n",
    "    environment = e.GenerateEnvironment()\n",
    "    print(e.genObs(environment),e.input_space)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1b2202c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 0)\n",
      "Action:  2 \n",
      "Environment: \n",
      " [[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]]] \n",
      "Reward 2\n",
      "False\n",
      "(2, 2, 1)\n",
      "Action:  2 \n",
      "Environment: \n",
      " [[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 0]]] \n",
      "Reward 2\n",
      "False\n",
      "(1, 2, 0)\n",
      "Action:  1 \n",
      "Environment: \n",
      " [[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 0]]] \n",
      "Reward 2\n",
      "False\n",
      "(0, 2, 0)\n",
      "Action:  0 \n",
      "Environment: \n",
      " [[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 0]]] \n",
      "Reward 2\n",
      "False\n",
      "(0, 2, 1)\n",
      "Action:  0 \n",
      "Environment: \n",
      " [[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 0]]] \n",
      "Reward 2\n",
      "False\n",
      "(2, 2, 2)\n",
      "Action:  2 \n",
      "Environment: \n",
      " [[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 1]]] \n",
      "Reward 2\n",
      "False\n",
      "(0, 2, 2)\n",
      "Action:  0 \n",
      "Environment: \n",
      " [[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 1]]] \n",
      "Reward 2\n",
      "False\n",
      "(0, 1, 0)\n",
      "Action:  0 \n",
      "Environment: \n",
      " [[[0 0 0]\n",
      "  [1 0 0]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 1]]] \n",
      "Reward 2\n",
      "False\n",
      "(0, 1, 1)\n",
      "Action:  0 \n",
      "Environment: \n",
      " [[[0 0 0]\n",
      "  [1 1 0]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 1]]] \n",
      "Reward 2\n",
      "False\n",
      "(1, 2, 1)\n",
      "Action:  1 \n",
      "Environment: \n",
      " [[[0 0 0]\n",
      "  [1 1 0]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 1]]] \n",
      "Reward 2\n",
      "False\n",
      "Test  [2, 2, 1, 0, 0, 2, 0, 0, 0, 1]  done\n",
      " [4. 7. 6.]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#UnitTests\n",
    "\n",
    "Steps = [[2,2,1,0,0,2,0,0,0,1]]\n",
    "\n",
    "for o in Steps:\n",
    "    e = Environment(size=(3,3,3))\n",
    "    environment = e.GenerateEnvironment()\n",
    "    \n",
    "    for i in o:\n",
    "        environment, reward, done = e.step(environment,i)\n",
    "        print(\"Action: \",i, \"\\nEnvironment: \\n\", environment, \"\\nReward\", reward)\n",
    "        print(done)\n",
    "    print(\"Test \",o,\" done\\n\",e.genObs(environment))\n",
    "    print(e.input_space)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022b6bfd",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Agent(\n",
    "    -Environment\n",
    "    -CNN\n",
    "    -Trainer)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Pseudo pseudocode\n",
    "<code>N = 10</code>\n",
    "\n",
    "<code>While True:</code><br>\n",
    "<code>    //Gaming moment (play 10 games)</code><br>\n",
    "<code>    for i in range(10):</code><br>\n",
    "<code>        pred = agent.pred()</code><br>\n",
    "<code>        agent.rememberMoves()</code><br>\n",
    "<code>    //Learning moment (train on previous games if possible)</code><br>\n",
    "<code>    agent.trainNN()</code><br>\n",
    "\n",
    "TODO: INCLUDE SCORING\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6f6c4",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cac1882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, lr, input_dims, n_actions, fc1_dims=64, fc2_dims=64):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1 = nn.Linear(self.input_dims, self.fc1_dims)\n",
    "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        self.fc3 = nn.Linear(self.fc2_dims, self.n_actions)\n",
    "        self.optimizer = optim.Adam(self.parameters(),lr=lr)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.to(self.device)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        actions = self.fc3(x)\n",
    "        \n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2945ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, gamma, lr, batch_size, max_mem_size=100000, size = (3,3,2),epsilon = 0.99, eps_end=0.01, eps_dec=5e-3):\n",
    "        \n",
    "        self.epsilon = epsilon\n",
    "        self.eps_min = eps_end\n",
    "        self.eps_dec = eps_dec\n",
    "        \n",
    "        \n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        #Create Environment\n",
    "        self.env = Environment(size)\n",
    "        \n",
    "        #self.action_space = self.env.action_space\n",
    "        self.action_space = [i for i in range(self.env.action_space)]\n",
    "        \n",
    "        #Create Convolutional Neural Network\n",
    "        self.Q_eval = DeepQNetwork(lr = lr, input_dims = self.env.input_space, n_actions = self.env.action_space)\n",
    "        \n",
    "        #Memory variables\n",
    "        self.mem_size = max_mem_size\n",
    "        self.mem_cntr = 0\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        #Memory array variables\n",
    "        self.state_memory = np.zeros((self.mem_size, self.env.input_space), dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, self.env.input_space), dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=bool)\n",
    "        \n",
    "    def chooseAction(self, observation):\n",
    "        if np.random.random() > self.epsilon:\n",
    "            #Turn observation into tensor\n",
    "            state = T.tensor([observation]).to(self.Q_eval.device)\n",
    "            #Get action from neural network\n",
    "            actions = self.Q_eval.forward(state)\n",
    "\n",
    "            #Get maximum value and return index\n",
    "            action = T.argmax(actions).item()\n",
    "        else:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        return action\n",
    "        \n",
    "    def rememberMoves(self, state, action, reward, state_, done):\n",
    "        #Makes counter loop over if max has been reached.\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        \n",
    "        #Save specific variables to arrays\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.reward_memory[index] = reward\n",
    "        self.action_memory[index] = action\n",
    "        self.terminal_memory[index] = done\n",
    "        \n",
    "        #Increment memory counter\n",
    "        self.mem_cntr += 1\n",
    "        \n",
    "    #TODO: We still need to add the trainer to this part.\n",
    "    def trainNN(self):\n",
    "        #If there's not enough memory for the batch size. Don't learn.\n",
    "        if self.mem_cntr < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        self.Q_eval.optimizer.zero_grad()\n",
    "        \n",
    "        #Check what the maximum size is of the memory\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "        \n",
    "        #Choose a random batch\n",
    "        batch = np.random.choice(max_mem, self.batch_size, replace=False)\n",
    "        \n",
    "        #Get batch indices for the batch size. (aka an array of batch_size int32s)\n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "        \n",
    "        #Load batch memory to device in tensors.\n",
    "        state_batch = T.tensor(self.state_memory[batch]).to(self.Q_eval.device)\n",
    "        new_state_batch = T.tensor(self.new_state_memory[batch]).to(self.Q_eval.device)\n",
    "        reward_batch = T.tensor(self.reward_memory[batch]).to(self.Q_eval.device)\n",
    "        terminal_batch = T.tensor(self.terminal_memory[batch]).to(self.Q_eval.device)\n",
    "        \n",
    "    \n",
    "        \n",
    "        #Load action batch memory.\n",
    "        action_batch = self.action_memory[batch]\n",
    "        \n",
    "        #Generate output for eval state.\n",
    "        q_eval = self.Q_eval.forward(state_batch)[batch_index, action_batch]\n",
    "        \n",
    "        #Generate output for next state.\n",
    "        q_next = self.Q_eval.forward(new_state_batch)\n",
    "        \n",
    "        #Done state gets reset for the terminal batch?? idk?\n",
    "        q_next[terminal_batch] = 0.0\n",
    "        \n",
    "        #Apply rewards to next batch.\n",
    "        q_target = reward_batch + self.gamma * T.max(q_next, dim=1)[0]\n",
    "        \n",
    "        loss = self.Q_eval.loss(q_target, q_eval).to(self.Q_eval.device)\n",
    "        loss.backward()\n",
    "        self.Q_eval.optimizer.step()\n",
    "        \n",
    "        self.epsilon = self.epsilon - self.eps_dec if self.epsilon > self.eps_min else self.eps_min\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1626db0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 106770/100000 score 9.30 epsilon 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m boardObservations\u001b[38;5;241m.\u001b[39mappend(env)\n\u001b[1;32m     31\u001b[0m obs \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mgenObs(env)\n\u001b[0;32m---> 32\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchooseAction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m newenv, reward, done \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(env,action)\n\u001b[1;32m     34\u001b[0m a\u001b[38;5;241m.\u001b[39mrememberMoves(a\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mgenObs(env), action, reward, a\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mgenObs(newenv), done)\n",
      "Cell \u001b[0;32mIn [7], line 38\u001b[0m, in \u001b[0;36mAgent.chooseAction\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     36\u001b[0m state \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mtensor([observation])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ_eval\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#Get action from neural network\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQ_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#Get maximum value and return index\u001b[39;00m\n\u001b[1;32m     41\u001b[0m action \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39margmax(actions)\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn [6], line 18\u001b[0m, in \u001b[0;36mDeepQNetwork.forward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[0;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[1;32m     20\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.9/site-packages/torch/nn/functional.py:1442\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1442\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a = Agent(0.3, 0.001, 64, size=(4, 4, 5))\n",
    "#env = a.env.GenerateEnvironment()\n",
    "\n",
    "#Geen prioriteit: Randomly invullen en kijken wat ie doet :)\n",
    "#Wel prioriteit: Randomly invullen en voeg score van de move toe.\n",
    "\n",
    "\n",
    "RewardHistory = []\n",
    "RewardHistoryHistory = []\n",
    "#TOFIX: Check if memory is programmed right?\n",
    "#TOFIX: Allow the training step to actually work.\n",
    "\n",
    "done = False\n",
    "n_games = 100000\n",
    "N = 10\n",
    "\n",
    "\n",
    "lastObservation = 0\n",
    "\n",
    "for o in range(n_games):\n",
    "    \n",
    "    nhistory = []\n",
    "    for i in range(N):\n",
    "        a.env.resetEnvironment()\n",
    "        env = a.env.GenerateEnvironment()\n",
    "        done = False\n",
    "        episodescore = []\n",
    "        boardObservations = []\n",
    "        while not done:\n",
    "            boardObservations.append(env)\n",
    "            obs = a.env.genObs(env)\n",
    "            action = a.chooseAction(obs)\n",
    "            newenv, reward, done = a.env.step(env,action)\n",
    "            a.rememberMoves(a.env.genObs(env), action, reward, a.env.genObs(newenv), done)\n",
    "            #if(o > 100 and i == 1):\n",
    "                #np.save('arrays.npy',boardObservations)\n",
    "                #clear_output(wait=True)\n",
    "                #print(\"Episode %i/%i score %.2f epsilon %.2f\"%(o*N,n_games,RewardHistory[-1],a.epsilon),flush=True)\n",
    "                #print(a.env.genObs(env),reward)\n",
    "            \n",
    "            env = newenv\n",
    "            episodescore.append(reward)\n",
    "        \n",
    "        if(o%100 == 0 and i == 0):\n",
    "            np.save('Observations/array%i.npy'%(o),boardObservations)\n",
    "        \n",
    "        nhistory.append(np.mean(episodescore))\n",
    "    a.trainNN()\n",
    "    RewardHistory.append(np.mean(nhistory))\n",
    "    \n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(\"Episode %i/%i score %.2f epsilon %.2f\"%(o*N,n_games,RewardHistory[-1],a.epsilon),flush=True)\n",
    "    #print(RewardHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1979c383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(RewardHistory)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualisation.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(trial):\n",
    "    lr = trial.suggest_float('lr', 1e-1, 1e-4, log=True)\n",
    "    \n",
    "    # process of training model\n",
    "    model = CNN(lr = lr, )\n",
    "    t = Trainer()\n",
    "    t.train\n",
    "    \n",
    "    return #score\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(trial, n_trials= 100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.Q_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c84bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f74f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
