{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35efba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cf1b0f3",
   "metadata": {},
   "source": [
    "https://github.com/philtabor/Youtube-Code-Repository/blob/master/ReinforcementLearning/PolicyGradient/PPO/torch/ppo_torch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc7bdd",
   "metadata": {},
   "source": [
    "# Agent class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2eb353c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOMemory:\n",
    "    def __init__(self, batch_size):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def generate_batches(self):\n",
    "        n_states = len(self.states)\n",
    "        batch_start = np.arange(0, n_states, self.batch_size)\n",
    "        indices = np.arange(n_states, dtype=np.int64)\n",
    "        np.random.shuffle(indices)\n",
    "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
    "\n",
    "        return np.array(self.states),\\\n",
    "                np.array(self.actions),\\\n",
    "                np.array(self.probs),\\\n",
    "                np.array(self.vals),\\\n",
    "                np.array(self.rewards),\\\n",
    "                np.array(self.dones),\\\n",
    "                batches\n",
    "\n",
    "    def store_memory(self, state, action, probs, vals, reward, done):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.probs.append(probs)\n",
    "        self.vals.append(vals)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.vals = []\n",
    "\n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, n_actions, input_dims, alpha,\n",
    "            fc1_dims=256, fc2_dims=256, chkpt_dir='tmp/ppo'):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'actor_torch_ppo')\n",
    "        self.actor = nn.Sequential(\n",
    "                nn.Linear(*input_dims, fc1_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc2_dims, n_actions),\n",
    "                nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        dist = self.actor(state)\n",
    "        dist = Categorical(dist)\n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, alpha, fc1_dims=256, fc2_dims=256,\n",
    "            chkpt_dir='tmp/ppo'):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'critic_torch_ppo')\n",
    "        self.critic = nn.Sequential(\n",
    "                nn.Linear(*input_dims, fc1_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc2_dims, 1)\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        value = self.critic(state)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, n_actions, input_dims, gamma=0.99, alpha=0.0003, gae_lambda=0.95,\n",
    "            policy_clip=0.2, batch_size=64, n_epochs=10):\n",
    "        self.gamma = gamma\n",
    "        self.policy_clip = policy_clip\n",
    "        self.n_epochs = n_epochs\n",
    "        self.gae_lambda = gae_lambda\n",
    "\n",
    "        self.actor = ActorNetwork(n_actions, input_dims, alpha)\n",
    "        self.critic = CriticNetwork(input_dims, alpha)\n",
    "        self.memory = PPOMemory(batch_size)\n",
    "       \n",
    "    def remember(self, state, action, probs, vals, reward, done):\n",
    "        self.memory.store_memory(state, action, probs, vals, reward, done)\n",
    "\n",
    "    def save_models(self):\n",
    "        print('... saving models ...')\n",
    "        self.actor.save_checkpoint()\n",
    "        self.critic.save_checkpoint()\n",
    "\n",
    "    def load_models(self):\n",
    "        print('... loading models ...')\n",
    "        self.actor.load_checkpoint()\n",
    "        self.critic.load_checkpoint()\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        state = T.tensor([observation], dtype=T.float).to(self.actor.device)\n",
    "\n",
    "        dist = self.actor(state)\n",
    "        value = self.critic(state)\n",
    "        action = dist.sample()\n",
    "        \n",
    "\n",
    "        probs = T.squeeze(dist.log_prob(action)).item()\n",
    "        action = T.squeeze(action).item()\n",
    "        value = T.squeeze(value).item()\n",
    "\n",
    "        return action, probs, value\n",
    "\n",
    "    def learn(self):\n",
    "        for _ in range(self.n_epochs):\n",
    "            state_arr, action_arr, old_prob_arr, vals_arr,\\\n",
    "            reward_arr, dones_arr, batches = \\\n",
    "                    self.memory.generate_batches()\n",
    "\n",
    "            values = vals_arr\n",
    "            advantage = np.zeros(len(reward_arr), dtype=np.float32)\n",
    "\n",
    "            for t in range(len(reward_arr)-1):\n",
    "                discount = 1\n",
    "                a_t = 0\n",
    "                for k in range(t, len(reward_arr)-1):\n",
    "                    a_t += discount*(reward_arr[k] + self.gamma*values[k+1]*\\\n",
    "                            (1-int(dones_arr[k])) - values[k])\n",
    "                    discount *= self.gamma*self.gae_lambda\n",
    "                advantage[t] = a_t\n",
    "            advantage = T.tensor(advantage).to(self.actor.device)\n",
    "\n",
    "            values = T.tensor(values).to(self.actor.device)\n",
    "            for batch in batches:\n",
    "                states = T.tensor(state_arr[batch], dtype=T.float).to(self.actor.device)\n",
    "                old_probs = T.tensor(old_prob_arr[batch]).to(self.actor.device)\n",
    "                actions = T.tensor(action_arr[batch]).to(self.actor.device)\n",
    "\n",
    "                dist = self.actor(states)\n",
    "                critic_value = self.critic(states)\n",
    "\n",
    "                critic_value = T.squeeze(critic_value)\n",
    "\n",
    "                new_probs = dist.log_prob(actions)\n",
    "                prob_ratio = new_probs.exp() / old_probs.exp()\n",
    "                #prob_ratio = (new_probs - old_probs).exp()\n",
    "                weighted_probs = advantage[batch] * prob_ratio\n",
    "                weighted_clipped_probs = T.clamp(prob_ratio, 1-self.policy_clip,\n",
    "                        1+self.policy_clip)*advantage[batch]\n",
    "                actor_loss = -T.min(weighted_probs, weighted_clipped_probs).mean()\n",
    "\n",
    "                returns = advantage[batch] + values[batch]\n",
    "                critic_loss = (returns-critic_value)**2\n",
    "                critic_loss = critic_loss.mean()\n",
    "\n",
    "                total_loss = actor_loss + 0.5*critic_loss\n",
    "                self.actor.optimizer.zero_grad()\n",
    "                self.critic.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.actor.optimizer.step()\n",
    "                self.critic.optimizer.step()\n",
    "\n",
    "        self.memory.clear_memory()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c089810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, size, posreward = 2, negreward = -2):\n",
    "        self.size = size\n",
    "        self.environment = np.array([[['0'] * self.size[2]] * self.size[1]] * self.size[0])\n",
    "        self.posreward = posreward\n",
    "        self.negreward = negreward\n",
    "        self.score = 0\n",
    "        self.done = False\n",
    "        self.envsize = self.environment.shape[0]*self.environment.shape[1]*self.environment.shape[2]\n",
    "        self.action_space = self.envsize*self.envsize\n",
    "        self.observation_space = [self.environment.shape[0]*self.environment.shape[1]*self.environment.shape[2]]\n",
    "    def resetField(self):\n",
    "        self.environment = np.array([[['0'] * self.size[2]] * self.size[1]] * self.size[0])\n",
    "        \n",
    "    def resetEnvironment(self):\n",
    "        self.resetField()\n",
    "        self.score = 0\n",
    "        self.done = False\n",
    "    \n",
    "    def genObs(self):\n",
    "        return np.array(self.environment.flatten() == '0', dtype=np.float32)\n",
    "    \n",
    "    def playGame(self,agout):\n",
    "        action_rows = np.reshape(agout,(e.envsize,e.envsize))\n",
    "        gameScore = 0\n",
    "        for i in action_rows:\n",
    "            oldState, newState, reward, done = self.step(np.argmax(i))\n",
    "            gameScore += reward\n",
    "            if self.done:\n",
    "                break\n",
    "                \n",
    "        #TODO: Add scoring moment for the entire board\n",
    "        \n",
    "        return gameScore, self.done\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        #Save Old State\n",
    "        oldState = self.environment.copy()\n",
    "        \n",
    "        #Make move\n",
    "        if self.placeContainer(np.unravel_index(action,self.environment.shape)):\n",
    "            #If move is allowed reward\n",
    "            reward = self.posreward\n",
    "        else:\n",
    "            #If move is not allowed punish\n",
    "            reward = self.negreward\n",
    "        \n",
    "        #Add to total score\n",
    "        self.score += reward\n",
    "        \n",
    "        #End game if field is all #s or if the user messed up.\n",
    "        if np.all(self.environment == '#') or reward == self.negreward:\n",
    "            self.done = True\n",
    "        return np.array(oldState == '0',dtype=np.float32).flatten(), np.array(self.environment == '0',dtype=np.float32).flatten(), action, reward, self.done \n",
    "    \n",
    "    def placeContainer(self, pos):\n",
    "        if self.isLegal(pos) and not self.done:\n",
    "            self.environment[pos] = '#'\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def isLegal(self, pos):\n",
    "        IO = self.isOccupied(pos)\n",
    "        IF = self.isFloating(pos)\n",
    "        IIE = self.posIsInEnv(pos)\n",
    "        NAS = self.hasNorthAndSouth(pos)\n",
    "        #print(IO,IF,IIE,NAS)\n",
    "        return not IO and not IF and IIE and not NAS\n",
    "    \n",
    "    def isOccupied(self, pos):\n",
    "        if self.posIsInEnv(pos):\n",
    "            return self.environment[pos] == '#'\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def hasNorthAndSouth(self, pos):\n",
    "        NC = self.isOccupied((pos[0],pos[1]-1,0))\n",
    "        SC = self.isOccupied((pos[0],pos[1]+1,0))\n",
    "        #print(NC,SC)\n",
    "        return NC and SC\n",
    "    \n",
    "    def posIsInEnv(self, pos):\n",
    "        x = 0 <= pos[0] < self.environment.shape[0]\n",
    "        y = 0 <= pos[1] < self.environment.shape[1]\n",
    "        z = 0 <= pos[2] < self.environment.shape[2]  \n",
    "        return x and y and z\n",
    "    \n",
    "    def isFloating(self, pos):\n",
    "        return np.any(self.environment[pos[0],pos[1],:pos[2]] == '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3fcd880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = Environment((3,3,3),negreward=-5)\n",
    "f = np.zeros(e.action_space)\n",
    "np.reshape(f,(e.envsize,e.envsize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a0e8e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 460 score -1.0 time_steps 1236 learning_steps 123\n",
      "tensor([[0.1347, 0.0005, 0.0013, 0.0054, 0.0021, 0.0016, 0.1035, 0.0008, 0.0011,\n",
      "         0.3861, 0.0007, 0.0006, 0.0019, 0.0029, 0.0006, 0.1652, 0.0006, 0.0009,\n",
      "         0.1245, 0.0007, 0.0014, 0.0247, 0.0021, 0.0004, 0.0348, 0.0004, 0.0004]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1341, 0.0008, 0.0017, 0.0068, 0.0027, 0.0022, 0.1041, 0.0011, 0.0016,\n",
      "         0.3478, 0.0011, 0.0009, 0.0026, 0.0038, 0.0008, 0.1757, 0.0008, 0.0013,\n",
      "         0.1365, 0.0011, 0.0020, 0.0290, 0.0027, 0.0006, 0.0370, 0.0006, 0.0006]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1347, 0.0005, 0.0013, 0.0054, 0.0021, 0.0016, 0.1035, 0.0008, 0.0011,\n",
      "         0.3861, 0.0007, 0.0006, 0.0019, 0.0029, 0.0006, 0.1652, 0.0006, 0.0009,\n",
      "         0.1245, 0.0007, 0.0014, 0.0247, 0.0021, 0.0004, 0.0348, 0.0004, 0.0004]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1284, 0.0008, 0.0017, 0.0066, 0.0026, 0.0022, 0.1026, 0.0011, 0.0016,\n",
      "         0.3750, 0.0011, 0.0009, 0.0026, 0.0039, 0.0009, 0.1715, 0.0009, 0.0013,\n",
      "         0.1253, 0.0011, 0.0019, 0.0278, 0.0029, 0.0006, 0.0335, 0.0006, 0.0006]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1347, 0.0005, 0.0013, 0.0054, 0.0021, 0.0016, 0.1035, 0.0008, 0.0011,\n",
      "         0.3861, 0.0007, 0.0006, 0.0019, 0.0029, 0.0006, 0.1652, 0.0006, 0.0009,\n",
      "         0.1245, 0.0007, 0.0014, 0.0247, 0.0021, 0.0004, 0.0348, 0.0004, 0.0004],\n",
      "        [0.1272, 0.0018, 0.0034, 0.0104, 0.0050, 0.0043, 0.1016, 0.0023, 0.0031,\n",
      "         0.3184, 0.0024, 0.0020, 0.0050, 0.0070, 0.0020, 0.1771, 0.0021, 0.0028,\n",
      "         0.1281, 0.0024, 0.0037, 0.0356, 0.0051, 0.0015, 0.0425, 0.0015, 0.0015],\n",
      "        [0.1299, 0.0008, 0.0018, 0.0068, 0.0030, 0.0022, 0.0926, 0.0012, 0.0017,\n",
      "         0.3630, 0.0011, 0.0009, 0.0027, 0.0042, 0.0009, 0.1832, 0.0009, 0.0013,\n",
      "         0.1260, 0.0010, 0.0020, 0.0255, 0.0028, 0.0007, 0.0426, 0.0007, 0.0006],\n",
      "        [0.1347, 0.0005, 0.0013, 0.0054, 0.0021, 0.0016, 0.1035, 0.0008, 0.0011,\n",
      "         0.3861, 0.0007, 0.0006, 0.0019, 0.0029, 0.0006, 0.1652, 0.0006, 0.0009,\n",
      "         0.1245, 0.0007, 0.0014, 0.0247, 0.0021, 0.0004, 0.0348, 0.0004, 0.0004],\n",
      "        [0.1341, 0.0008, 0.0017, 0.0068, 0.0027, 0.0022, 0.1041, 0.0011, 0.0016,\n",
      "         0.3478, 0.0011, 0.0009, 0.0026, 0.0038, 0.0008, 0.1757, 0.0008, 0.0013,\n",
      "         0.1365, 0.0011, 0.0020, 0.0290, 0.0027, 0.0006, 0.0370, 0.0006, 0.0006],\n",
      "        [0.1347, 0.0005, 0.0013, 0.0054, 0.0021, 0.0016, 0.1035, 0.0008, 0.0011,\n",
      "         0.3861, 0.0007, 0.0006, 0.0019, 0.0029, 0.0006, 0.1652, 0.0006, 0.0009,\n",
      "         0.1245, 0.0007, 0.0014, 0.0247, 0.0021, 0.0004, 0.0348, 0.0004, 0.0004],\n",
      "        [0.1174, 0.0024, 0.0045, 0.0127, 0.0063, 0.0055, 0.0996, 0.0032, 0.0041,\n",
      "         0.2917, 0.0034, 0.0028, 0.0064, 0.0086, 0.0027, 0.1834, 0.0030, 0.0037,\n",
      "         0.1324, 0.0033, 0.0047, 0.0392, 0.0066, 0.0020, 0.0462, 0.0021, 0.0021],\n",
      "        [0.1284, 0.0008, 0.0017, 0.0066, 0.0026, 0.0022, 0.1026, 0.0011, 0.0016,\n",
      "         0.3750, 0.0011, 0.0009, 0.0026, 0.0039, 0.0009, 0.1715, 0.0009, 0.0013,\n",
      "         0.1253, 0.0011, 0.0019, 0.0278, 0.0029, 0.0006, 0.0335, 0.0006, 0.0006],\n",
      "        [0.1276, 0.0006, 0.0015, 0.0059, 0.0026, 0.0019, 0.0887, 0.0010, 0.0014,\n",
      "         0.3797, 0.0009, 0.0007, 0.0023, 0.0035, 0.0007, 0.1804, 0.0007, 0.0011,\n",
      "         0.1305, 0.0009, 0.0017, 0.0243, 0.0023, 0.0005, 0.0376, 0.0005, 0.0005],\n",
      "        [0.1262, 0.0014, 0.0029, 0.0093, 0.0043, 0.0038, 0.0978, 0.0020, 0.0026,\n",
      "         0.3342, 0.0020, 0.0017, 0.0044, 0.0060, 0.0016, 0.1764, 0.0017, 0.0023,\n",
      "         0.1338, 0.0020, 0.0030, 0.0344, 0.0044, 0.0012, 0.0382, 0.0012, 0.0012]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1333, 0.0008, 0.0017, 0.0066, 0.0026, 0.0022, 0.1056, 0.0011, 0.0015,\n",
      "         0.3575, 0.0010, 0.0008, 0.0025, 0.0038, 0.0008, 0.1795, 0.0008, 0.0013,\n",
      "         0.1243, 0.0010, 0.0019, 0.0283, 0.0027, 0.0006, 0.0364, 0.0006, 0.0006],\n",
      "        [0.1272, 0.0008, 0.0017, 0.0064, 0.0026, 0.0022, 0.1038, 0.0011, 0.0015,\n",
      "         0.3852, 0.0010, 0.0009, 0.0026, 0.0039, 0.0008, 0.1747, 0.0009, 0.0013,\n",
      "         0.1139, 0.0011, 0.0018, 0.0271, 0.0028, 0.0006, 0.0329, 0.0006, 0.0006],\n",
      "        [0.1290, 0.0008, 0.0018, 0.0066, 0.0030, 0.0021, 0.0938, 0.0011, 0.0016,\n",
      "         0.3728, 0.0010, 0.0008, 0.0026, 0.0041, 0.0009, 0.1866, 0.0009, 0.0013,\n",
      "         0.1145, 0.0010, 0.0020, 0.0249, 0.0027, 0.0007, 0.0420, 0.0006, 0.0006],\n",
      "        [0.1172, 0.0024, 0.0044, 0.0125, 0.0062, 0.0054, 0.1010, 0.0031, 0.0040,\n",
      "         0.2986, 0.0033, 0.0028, 0.0063, 0.0086, 0.0026, 0.1869, 0.0029, 0.0037,\n",
      "         0.1233, 0.0032, 0.0046, 0.0386, 0.0065, 0.0020, 0.0458, 0.0021, 0.0021],\n",
      "        [0.1255, 0.0014, 0.0028, 0.0091, 0.0042, 0.0037, 0.0992, 0.0019, 0.0026,\n",
      "         0.3430, 0.0020, 0.0016, 0.0043, 0.0059, 0.0015, 0.1799, 0.0017, 0.0023,\n",
      "         0.1231, 0.0020, 0.0030, 0.0337, 0.0044, 0.0012, 0.0377, 0.0012, 0.0012],\n",
      "        [0.1334, 0.0005, 0.0012, 0.0052, 0.0020, 0.0015, 0.1048, 0.0008, 0.0011,\n",
      "         0.3970, 0.0007, 0.0006, 0.0019, 0.0029, 0.0006, 0.1684, 0.0006, 0.0009,\n",
      "         0.1125, 0.0007, 0.0014, 0.0241, 0.0020, 0.0004, 0.0341, 0.0004, 0.0004],\n",
      "        [0.1334, 0.0005, 0.0012, 0.0052, 0.0020, 0.0015, 0.1048, 0.0008, 0.0011,\n",
      "         0.3970, 0.0007, 0.0006, 0.0019, 0.0029, 0.0006, 0.1684, 0.0006, 0.0009,\n",
      "         0.1125, 0.0007, 0.0014, 0.0241, 0.0020, 0.0004, 0.0341, 0.0004, 0.0004],\n",
      "        [0.1268, 0.0018, 0.0033, 0.0102, 0.0049, 0.0042, 0.1029, 0.0023, 0.0031,\n",
      "         0.3262, 0.0024, 0.0020, 0.0050, 0.0069, 0.0019, 0.1805, 0.0020, 0.0028,\n",
      "         0.1184, 0.0024, 0.0036, 0.0349, 0.0051, 0.0015, 0.0420, 0.0015, 0.0015],\n",
      "        [0.1266, 0.0006, 0.0015, 0.0057, 0.0025, 0.0018, 0.0897, 0.0009, 0.0014,\n",
      "         0.3903, 0.0008, 0.0007, 0.0022, 0.0035, 0.0007, 0.1840, 0.0007, 0.0011,\n",
      "         0.1182, 0.0008, 0.0016, 0.0237, 0.0023, 0.0005, 0.0370, 0.0005, 0.0005],\n",
      "        [0.1334, 0.0005, 0.0012, 0.0052, 0.0020, 0.0015, 0.1048, 0.0008, 0.0011,\n",
      "         0.3970, 0.0007, 0.0006, 0.0019, 0.0029, 0.0006, 0.1684, 0.0006, 0.0009,\n",
      "         0.1125, 0.0007, 0.0014, 0.0241, 0.0020, 0.0004, 0.0341, 0.0004, 0.0004]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2556e-01, 7.5869e-04, 1.6098e-03, 6.2528e-03, 2.4785e-03, 2.1063e-03,\n",
      "         1.0472e-01, 1.0610e-03, 1.4793e-03, 3.9576e-01, 9.8859e-04, 8.3410e-04,\n",
      "         2.5145e-03, 3.8044e-03, 8.1157e-04, 1.7834e-01, 8.4534e-04, 1.2542e-03,\n",
      "         1.0274e-01, 1.0557e-03, 1.7582e-03, 2.6218e-02, 2.7636e-03, 6.1594e-04,\n",
      "         3.2455e-02, 6.1052e-04, 6.1103e-04],\n",
      "        [1.3154e-01, 5.1115e-04, 1.1828e-03, 5.0755e-03, 1.9553e-03, 1.4885e-03,\n",
      "         1.0568e-01, 7.6119e-04, 1.0568e-03, 4.0818e-01, 6.6643e-04, 5.4810e-04,\n",
      "         1.8221e-03, 2.8303e-03, 5.4797e-04, 1.7199e-01, 5.3572e-04, 8.6735e-04,\n",
      "         1.0073e-01, 6.9324e-04, 1.3242e-03, 2.3206e-02, 1.9938e-03, 4.2071e-04,\n",
      "         3.3606e-02, 3.9616e-04, 3.9712e-04],\n",
      "        [1.3154e-01, 5.1115e-04, 1.1828e-03, 5.0755e-03, 1.9553e-03, 1.4885e-03,\n",
      "         1.0568e-01, 7.6119e-04, 1.0568e-03, 4.0818e-01, 6.6643e-04, 5.4810e-04,\n",
      "         1.8221e-03, 2.8303e-03, 5.4797e-04, 1.7199e-01, 5.3572e-04, 8.6735e-04,\n",
      "         1.0073e-01, 6.9324e-04, 1.3242e-03, 2.3206e-02, 1.9938e-03, 4.2071e-04,\n",
      "         3.3606e-02, 3.9616e-04, 3.9712e-04],\n",
      "        [1.3198e-01, 7.4227e-04, 1.6382e-03, 6.4661e-03, 2.5659e-03, 2.0953e-03,\n",
      "         1.0678e-01, 1.0798e-03, 1.4848e-03, 3.6745e-01, 1.0144e-03, 8.2622e-04,\n",
      "         2.4909e-03, 3.7171e-03, 8.0355e-04, 1.8371e-01, 8.0738e-04, 1.2524e-03,\n",
      "         1.1235e-01, 1.0208e-03, 1.8503e-03, 2.7447e-02, 2.6558e-03, 6.0729e-04,\n",
      "         3.5999e-02, 5.8807e-04, 5.7431e-04],\n",
      "        [1.2757e-01, 7.9656e-04, 1.7477e-03, 6.3945e-03, 2.8628e-03, 2.0629e-03,\n",
      "         9.4694e-02, 1.1183e-03, 1.5890e-03, 3.8290e-01, 1.0175e-03, 8.2177e-04,\n",
      "         2.5333e-03, 4.0544e-03, 8.6311e-04, 1.9056e-01, 8.6166e-04, 1.2901e-03,\n",
      "         1.0330e-01, 1.0074e-03, 1.9299e-03, 2.4040e-02, 2.6722e-03, 6.4913e-04,\n",
      "         4.1414e-02, 6.2975e-04, 6.1884e-04],\n",
      "        [1.3154e-01, 5.1115e-04, 1.1828e-03, 5.0755e-03, 1.9553e-03, 1.4885e-03,\n",
      "         1.0568e-01, 7.6119e-04, 1.0568e-03, 4.0818e-01, 6.6643e-04, 5.4810e-04,\n",
      "         1.8221e-03, 2.8303e-03, 5.4797e-04, 1.7199e-01, 5.3572e-04, 8.6735e-04,\n",
      "         1.0073e-01, 6.9324e-04, 1.3242e-03, 2.3206e-02, 1.9938e-03, 4.2071e-04,\n",
      "         3.3606e-02, 3.9616e-04, 3.9712e-04],\n",
      "        [1.2505e-01, 6.1202e-04, 1.4244e-03, 5.5657e-03, 2.4038e-03, 1.7609e-03,\n",
      "         9.0563e-02, 9.0486e-04, 1.3223e-03, 4.0117e-01, 8.2284e-04, 6.5047e-04,\n",
      "         2.1426e-03, 3.4351e-03, 6.7427e-04, 1.8810e-01, 6.8503e-04, 1.0618e-03,\n",
      "         1.0614e-01, 8.2970e-04, 1.5575e-03, 2.2901e-02, 2.2401e-03, 5.0841e-04,\n",
      "         3.6486e-02, 5.0191e-04, 4.8771e-04],\n",
      "        [1.2440e-01, 1.3657e-03, 2.7378e-03, 8.9108e-03, 4.0557e-03, 3.6144e-03,\n",
      "         1.0027e-01, 1.8670e-03, 2.5206e-03, 3.5229e-01, 1.9290e-03, 1.5772e-03,\n",
      "         4.1984e-03, 5.8693e-03, 1.5122e-03, 1.8377e-01, 1.6307e-03, 2.2694e-03,\n",
      "         1.1252e-01, 1.9621e-03, 2.9008e-03, 3.2701e-02, 4.2828e-03, 1.1577e-03,\n",
      "         3.7336e-02, 1.1783e-03, 1.1684e-03],\n",
      "        [1.1651e-01, 2.3365e-03, 4.3217e-03, 1.2244e-02, 6.0419e-03, 5.2666e-03,\n",
      "         1.0224e-01, 3.0452e-03, 3.9218e-03, 3.0596e-01, 3.2346e-03, 2.7146e-03,\n",
      "         6.2145e-03, 8.5042e-03, 2.5734e-03, 1.9080e-01, 2.8771e-03, 3.6085e-03,\n",
      "         1.1420e-01, 3.1656e-03, 4.5522e-03, 3.7642e-02, 6.4463e-03, 1.9969e-03,\n",
      "         4.5499e-02, 2.0509e-03, 2.0457e-03],\n",
      "        [1.2588e-01, 1.7437e-03, 3.2709e-03, 9.9845e-03, 4.7576e-03, 4.1381e-03,\n",
      "         1.0412e-01, 2.2541e-03, 2.9896e-03, 3.3445e-01, 2.3348e-03, 1.9463e-03,\n",
      "         4.8635e-03, 6.8369e-03, 1.9019e-03, 1.8422e-01, 1.9937e-03, 2.7158e-03,\n",
      "         1.0880e-01, 2.3334e-03, 3.5309e-03, 3.3915e-02, 4.9818e-03, 1.4448e-03,\n",
      "         4.1694e-02, 1.4523e-03, 1.4517e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2557e-01, 7.7901e-04, 1.6969e-03, 6.2034e-03, 2.7676e-03, 1.9956e-03,\n",
      "         9.5276e-02, 1.0861e-03, 1.5463e-03, 3.9309e-01, 9.8481e-04, 7.9708e-04,\n",
      "         2.4705e-03, 3.9953e-03, 8.3976e-04, 1.9487e-01, 8.3757e-04, 1.2605e-03,\n",
      "         9.2589e-02, 9.8327e-04, 1.8679e-03, 2.3030e-02, 2.6198e-03, 6.3768e-04,\n",
      "         4.0983e-02, 6.1335e-04, 6.0624e-04],\n",
      "        [1.2449e-01, 1.7107e-03, 3.1917e-03, 9.7430e-03, 4.6222e-03, 4.0224e-03,\n",
      "         1.0510e-01, 2.2031e-03, 2.9220e-03, 3.4307e-01, 2.2740e-03, 1.8984e-03,\n",
      "         4.7713e-03, 6.7711e-03, 1.8606e-03, 1.8831e-01, 1.9496e-03, 2.6615e-03,\n",
      "         9.9425e-02, 2.2880e-03, 3.4388e-03, 3.2675e-02, 4.8963e-03, 1.4243e-03,\n",
      "         4.1441e-02, 1.4194e-03, 1.4262e-03],\n",
      "        [1.1544e-01, 2.2967e-03, 4.2275e-03, 1.1980e-02, 5.8864e-03, 5.1344e-03,\n",
      "         1.0326e-01, 2.9845e-03, 3.8442e-03, 3.1377e-01, 3.1611e-03, 2.6549e-03,\n",
      "         6.1115e-03, 8.4444e-03, 2.5242e-03, 1.9507e-01, 2.8201e-03, 3.5447e-03,\n",
      "         1.0524e-01, 3.1111e-03, 4.4463e-03, 3.6384e-02, 6.3503e-03, 1.9725e-03,\n",
      "         4.5317e-02, 2.0098e-03, 2.0143e-03],\n",
      "        [1.2915e-01, 4.9888e-04, 1.1461e-03, 4.9134e-03, 1.8851e-03, 1.4367e-03,\n",
      "         1.0625e-01, 7.3727e-04, 1.0259e-03, 4.1931e-01, 6.4307e-04, 5.3011e-04,\n",
      "         1.7728e-03, 2.7824e-03, 5.3167e-04, 1.7594e-01, 5.1977e-04, 8.4532e-04,\n",
      "         8.9645e-02, 6.7531e-04, 1.2789e-03, 2.2155e-02, 1.9506e-03, 4.1257e-04,\n",
      "         3.3187e-02, 3.8486e-04, 3.8810e-04],\n",
      "        [1.2295e-01, 5.9790e-04, 1.3811e-03, 5.3926e-03, 2.3202e-03, 1.7009e-03,\n",
      "         9.1088e-02, 8.7758e-04, 1.2851e-03, 4.1201e-01, 7.9523e-04, 6.3014e-04,\n",
      "         2.0865e-03, 3.3812e-03, 6.5523e-04, 1.9252e-01, 6.6514e-04, 1.0363e-03,\n",
      "         9.4678e-02, 8.0896e-04, 1.5053e-03, 2.1903e-02, 2.1943e-03, 4.9898e-04,\n",
      "         3.6073e-02, 4.8832e-04, 4.7727e-04],\n",
      "        [1.2915e-01, 4.9888e-04, 1.1461e-03, 4.9134e-03, 1.8851e-03, 1.4367e-03,\n",
      "         1.0625e-01, 7.3727e-04, 1.0259e-03, 4.1931e-01, 6.4307e-04, 5.3011e-04,\n",
      "         1.7728e-03, 2.7824e-03, 5.3167e-04, 1.7594e-01, 5.1977e-04, 8.4532e-04,\n",
      "         8.9645e-02, 6.7531e-04, 1.2789e-03, 2.2155e-02, 1.9506e-03, 4.1257e-04,\n",
      "         3.3187e-02, 3.8486e-04, 3.8810e-04],\n",
      "        [1.2281e-01, 1.3383e-03, 2.6683e-03, 8.6834e-03, 3.9341e-03, 3.5092e-03,\n",
      "         1.0118e-01, 1.8215e-03, 2.4601e-03, 3.6179e-01, 1.8754e-03, 1.5352e-03,\n",
      "         4.1117e-03, 5.8056e-03, 1.4772e-03, 1.8799e-01, 1.5928e-03, 2.2217e-03,\n",
      "         1.0231e-01, 1.9225e-03, 2.8212e-03, 3.1448e-02, 4.2050e-03, 1.1406e-03,\n",
      "         3.7060e-02, 1.1502e-03, 1.1465e-03],\n",
      "        [1.3012e-01, 7.2736e-04, 1.5935e-03, 6.2865e-03, 2.4844e-03, 2.0307e-03,\n",
      "         1.0768e-01, 1.0509e-03, 1.4474e-03, 3.7744e-01, 9.8385e-04, 8.0319e-04,\n",
      "         2.4332e-03, 3.6680e-03, 7.8315e-04, 1.8835e-01, 7.8635e-04, 1.2256e-03,\n",
      "         1.0095e-01, 9.9820e-04, 1.7947e-03, 2.6349e-02, 2.6085e-03, 5.9757e-04,\n",
      "         3.5674e-02, 5.7388e-04, 5.6339e-04],\n",
      "        [1.2915e-01, 4.9888e-04, 1.1461e-03, 4.9134e-03, 1.8851e-03, 1.4367e-03,\n",
      "         1.0625e-01, 7.3727e-04, 1.0259e-03, 4.1931e-01, 6.4307e-04, 5.3011e-04,\n",
      "         1.7728e-03, 2.7824e-03, 5.3167e-04, 1.7594e-01, 5.1977e-04, 8.4532e-04,\n",
      "         8.9645e-02, 6.7531e-04, 1.2789e-03, 2.2155e-02, 1.9506e-03, 4.1257e-04,\n",
      "         3.3187e-02, 3.8486e-04, 3.8810e-04],\n",
      "        [1.2340e-01, 7.4136e-04, 1.5625e-03, 6.0671e-03, 2.3944e-03, 2.0365e-03,\n",
      "         1.0532e-01, 1.0294e-03, 1.4388e-03, 4.0629e-01, 9.5599e-04, 8.0799e-04,\n",
      "         2.4500e-03, 3.7443e-03, 7.8882e-04, 1.8234e-01, 8.2149e-04, 1.2242e-03,\n",
      "         9.2163e-02, 1.0299e-03, 1.7014e-03, 2.5098e-02, 2.7067e-03, 6.0479e-04,\n",
      "         3.2088e-02, 5.9417e-04, 5.9782e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1141, 0.0010, 0.0021, 0.0073, 0.0030, 0.0026, 0.1048, 0.0014, 0.0019,\n",
      "         0.3888, 0.0013, 0.0011, 0.0031, 0.0048, 0.0011, 0.1968, 0.0012, 0.0016,\n",
      "         0.0899, 0.0014, 0.0022, 0.0270, 0.0035, 0.0008, 0.0355, 0.0008, 0.0008]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1131, 0.0012, 0.0025, 0.0083, 0.0037, 0.0031, 0.1020, 0.0017, 0.0023,\n",
      "         0.3875, 0.0017, 0.0014, 0.0039, 0.0056, 0.0014, 0.1900, 0.0015, 0.0020,\n",
      "         0.0887, 0.0018, 0.0026, 0.0285, 0.0041, 0.0011, 0.0379, 0.0011, 0.0011]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1128, 0.0018, 0.0035, 0.0104, 0.0048, 0.0043, 0.1019, 0.0024, 0.0032,\n",
      "         0.3406, 0.0026, 0.0021, 0.0052, 0.0072, 0.0020, 0.1994, 0.0023, 0.0029,\n",
      "         0.1001, 0.0026, 0.0036, 0.0338, 0.0054, 0.0016, 0.0405, 0.0016, 0.0016]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1089, 0.0021, 0.0041, 0.0113, 0.0057, 0.0050, 0.0899, 0.0028, 0.0039,\n",
      "         0.3279, 0.0030, 0.0024, 0.0060, 0.0084, 0.0024, 0.2111, 0.0028, 0.0034,\n",
      "         0.1035, 0.0030, 0.0042, 0.0335, 0.0059, 0.0018, 0.0432, 0.0019, 0.0019]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2645e-01, 4.8736e-04, 1.1139e-03, 4.7706e-03, 1.8223e-03, 1.3886e-03,\n",
      "         1.0654e-01, 7.1603e-04, 9.9827e-04, 4.2824e-01, 6.2280e-04, 5.1379e-04,\n",
      "         1.7297e-03, 2.7419e-03, 5.1675e-04, 1.8027e-01, 5.0586e-04, 8.2456e-04,\n",
      "         8.0817e-02, 6.5846e-04, 1.2383e-03, 2.1031e-02, 1.9108e-03, 4.0517e-04,\n",
      "         3.2936e-02, 3.7494e-04, 3.7980e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1278, 0.0007, 0.0016, 0.0061, 0.0024, 0.0020, 0.1083, 0.0010, 0.0014,\n",
      "         0.3856, 0.0010, 0.0008, 0.0024, 0.0036, 0.0008, 0.1932, 0.0008, 0.0012,\n",
      "         0.0918, 0.0010, 0.0017, 0.0251, 0.0026, 0.0006, 0.0355, 0.0006, 0.0006]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2645e-01, 4.8736e-04, 1.1139e-03, 4.7706e-03, 1.8223e-03, 1.3886e-03,\n",
      "         1.0654e-01, 7.1603e-04, 9.9827e-04, 4.2824e-01, 6.2280e-04, 5.1379e-04,\n",
      "         1.7297e-03, 2.7419e-03, 5.1675e-04, 1.8027e-01, 5.0586e-04, 8.2456e-04,\n",
      "         8.0817e-02, 6.5846e-04, 1.2383e-03, 2.1031e-02, 1.9108e-03, 4.0517e-04,\n",
      "         3.2936e-02, 3.7494e-04, 3.7980e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1196, 0.0007, 0.0015, 0.0060, 0.0024, 0.0018, 0.1059, 0.0010, 0.0014,\n",
      "         0.4027, 0.0009, 0.0007, 0.0023, 0.0036, 0.0007, 0.1915, 0.0008, 0.0012,\n",
      "         0.0875, 0.0009, 0.0017, 0.0241, 0.0026, 0.0006, 0.0368, 0.0006, 0.0006]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1133, 0.0008, 0.0019, 0.0066, 0.0030, 0.0022, 0.0910, 0.0012, 0.0017,\n",
      "         0.3944, 0.0011, 0.0009, 0.0027, 0.0043, 0.0009, 0.2082, 0.0010, 0.0014,\n",
      "         0.0919, 0.0011, 0.0020, 0.0236, 0.0029, 0.0007, 0.0399, 0.0007, 0.0007]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1132, 0.0012, 0.0026, 0.0085, 0.0039, 0.0030, 0.0921, 0.0017, 0.0024,\n",
      "         0.3498, 0.0017, 0.0013, 0.0037, 0.0056, 0.0013, 0.2192, 0.0015, 0.0020,\n",
      "         0.1038, 0.0016, 0.0027, 0.0279, 0.0038, 0.0010, 0.0423, 0.0010, 0.0010]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.1326e-01, 8.1819e-04, 1.8542e-03, 6.6307e-03, 2.9710e-03, 2.1624e-03,\n",
      "         9.0963e-02, 1.1997e-03, 1.7090e-03, 3.9440e-01, 1.1147e-03, 8.8589e-04,\n",
      "         2.7116e-03, 4.3426e-03, 9.0144e-04, 2.0822e-01, 9.7494e-04, 1.4073e-03,\n",
      "         9.1896e-02, 1.1153e-03, 1.9539e-03, 2.3627e-02, 2.8733e-03, 7.0718e-04,\n",
      "         3.9911e-02, 7.0505e-04, 6.8371e-04],\n",
      "        [1.1284e-01, 1.7690e-03, 3.4568e-03, 1.0436e-02, 4.8340e-03, 4.3447e-03,\n",
      "         1.0186e-01, 2.4101e-03, 3.1703e-03, 3.4060e-01, 2.5523e-03, 2.0953e-03,\n",
      "         5.2112e-03, 7.2069e-03, 1.9722e-03, 1.9944e-01, 2.2682e-03, 2.9091e-03,\n",
      "         1.0014e-01, 2.5656e-03, 3.5816e-03, 3.3780e-02, 5.3585e-03, 1.5667e-03,\n",
      "         4.0460e-02, 1.6013e-03, 1.5864e-03],\n",
      "        [1.1305e-01, 1.2494e-03, 2.5240e-03, 8.3164e-03, 3.7346e-03, 3.1437e-03,\n",
      "         1.0202e-01, 1.7075e-03, 2.2850e-03, 3.8751e-01, 1.6942e-03, 1.3963e-03,\n",
      "         3.8519e-03, 5.6262e-03, 1.3758e-03, 1.8998e-01, 1.5251e-03, 2.0448e-03,\n",
      "         8.8743e-02, 1.7854e-03, 2.5967e-03, 2.8534e-02, 4.1093e-03, 1.1118e-03,\n",
      "         3.7855e-02, 1.0970e-03, 1.1290e-03],\n",
      "        [1.1957e-01, 6.8323e-04, 1.5262e-03, 5.9799e-03, 2.4265e-03, 1.8336e-03,\n",
      "         1.0594e-01, 1.0099e-03, 1.3681e-03, 4.0273e-01, 9.0179e-04, 7.3969e-04,\n",
      "         2.2954e-03, 3.6019e-03, 7.3343e-04, 1.9150e-01, 7.5855e-04, 1.1530e-03,\n",
      "         8.7470e-02, 9.2605e-04, 1.6574e-03, 2.4104e-02, 2.5525e-03, 5.8608e-04,\n",
      "         3.6835e-02, 5.5957e-04, 5.5948e-04],\n",
      "        [1.2784e-01, 7.1214e-04, 1.5533e-03, 6.1247e-03, 2.4080e-03, 1.9686e-03,\n",
      "         1.0832e-01, 1.0255e-03, 1.4121e-03, 3.8559e-01, 9.5740e-04, 7.8183e-04,\n",
      "         2.3833e-03, 3.6286e-03, 7.6439e-04, 1.9320e-01, 7.6843e-04, 1.1984e-03,\n",
      "         9.1759e-02, 9.7695e-04, 1.7444e-03, 2.5108e-02, 2.5597e-03, 5.8845e-04,\n",
      "         3.5510e-02, 5.6056e-04, 5.5254e-04],\n",
      "        [1.0890e-01, 2.0952e-03, 4.0840e-03, 1.1287e-02, 5.7149e-03, 5.0275e-03,\n",
      "         8.9908e-02, 2.7597e-03, 3.8707e-03, 3.2786e-01, 3.0403e-03, 2.4330e-03,\n",
      "         5.9766e-03, 8.3930e-03, 2.3904e-03, 2.1112e-01, 2.8051e-03, 3.4403e-03,\n",
      "         1.0352e-01, 3.0219e-03, 4.1646e-03, 3.3469e-02, 5.9123e-03, 1.8353e-03,\n",
      "         4.3157e-02, 1.9380e-03, 1.8823e-03],\n",
      "        [1.2645e-01, 4.8736e-04, 1.1139e-03, 4.7706e-03, 1.8223e-03, 1.3886e-03,\n",
      "         1.0654e-01, 7.1603e-04, 9.9827e-04, 4.2824e-01, 6.2280e-04, 5.1379e-04,\n",
      "         1.7297e-03, 2.7419e-03, 5.1675e-04, 1.8027e-01, 5.0586e-04, 8.2456e-04,\n",
      "         8.0817e-02, 6.5846e-04, 1.2383e-03, 2.1031e-02, 1.9108e-03, 4.0517e-04,\n",
      "         3.2936e-02, 3.7494e-04, 3.7980e-04],\n",
      "        [1.1324e-01, 1.1876e-03, 2.5852e-03, 8.5152e-03, 3.8745e-03, 3.0420e-03,\n",
      "         9.2064e-02, 1.6967e-03, 2.3902e-03, 3.4978e-01, 1.6855e-03, 1.3464e-03,\n",
      "         3.7057e-03, 5.6362e-03, 1.3148e-03, 2.1920e-01, 1.4688e-03, 2.0125e-03,\n",
      "         1.0380e-01, 1.6348e-03, 2.7416e-03, 2.7938e-02, 3.8320e-03, 1.0156e-03,\n",
      "         4.2277e-02, 1.0413e-03, 9.7923e-04],\n",
      "        [1.2645e-01, 4.8736e-04, 1.1139e-03, 4.7706e-03, 1.8223e-03, 1.3886e-03,\n",
      "         1.0654e-01, 7.1603e-04, 9.9827e-04, 4.2824e-01, 6.2280e-04, 5.1379e-04,\n",
      "         1.7297e-03, 2.7419e-03, 5.1675e-04, 1.8027e-01, 5.0586e-04, 8.2456e-04,\n",
      "         8.0817e-02, 6.5846e-04, 1.2383e-03, 2.1031e-02, 1.9108e-03, 4.0517e-04,\n",
      "         3.2936e-02, 3.7494e-04, 3.7980e-04],\n",
      "        [1.1414e-01, 9.9376e-04, 2.0584e-03, 7.3422e-03, 3.0236e-03, 2.5538e-03,\n",
      "         1.0481e-01, 1.3893e-03, 1.8966e-03, 3.8883e-01, 1.3224e-03, 1.1118e-03,\n",
      "         3.1179e-03, 4.7924e-03, 1.0763e-03, 1.9682e-01, 1.1792e-03, 1.6318e-03,\n",
      "         8.9855e-02, 1.4001e-03, 2.1833e-03, 2.6964e-02, 3.4864e-03, 8.4051e-04,\n",
      "         3.5499e-02, 8.4477e-04, 8.3882e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1858e-01, 6.7026e-04, 1.4889e-03, 5.8360e-03, 2.3550e-03, 1.7833e-03,\n",
      "         1.0677e-01, 9.8644e-04, 1.3357e-03, 4.0803e-01, 8.7725e-04, 7.2134e-04,\n",
      "         2.2482e-03, 3.5596e-03, 7.1625e-04, 1.9582e-01, 7.4110e-04, 1.1279e-03,\n",
      "         7.9965e-02, 9.0639e-04, 1.6143e-03, 2.3065e-02, 2.5063e-03, 5.7694e-04,\n",
      "         3.6627e-02, 5.4648e-04, 5.4899e-04],\n",
      "        [1.2690e-01, 6.9888e-04, 1.5163e-03, 5.9800e-03, 2.3377e-03, 1.9154e-03,\n",
      "         1.0932e-01, 1.0031e-03, 1.3793e-03, 3.9078e-01, 9.3261e-04, 7.6324e-04,\n",
      "         2.3373e-03, 3.5909e-03, 7.4727e-04, 1.9775e-01, 7.5173e-04, 1.1727e-03,\n",
      "         8.3905e-02, 9.5733e-04, 1.7007e-03, 2.4024e-02, 2.5137e-03, 5.7974e-04,\n",
      "         3.5350e-02, 5.4761e-04, 5.4238e-04],\n",
      "        [1.0835e-01, 2.0644e-03, 4.0068e-03, 1.1074e-02, 5.5844e-03, 4.9171e-03,\n",
      "         9.0800e-02, 2.7145e-03, 3.8030e-03, 3.3257e-01, 2.9801e-03, 2.3871e-03,\n",
      "         5.8908e-03, 8.3409e-03, 2.3492e-03, 2.1574e-01, 2.7594e-03, 3.3821e-03,\n",
      "         9.6466e-02, 2.9765e-03, 4.0812e-03, 3.2256e-02, 5.8276e-03, 1.8170e-03,\n",
      "         4.3100e-02, 1.9026e-03, 1.8568e-03],\n",
      "        [1.2526e-01, 4.7695e-04, 1.0841e-03, 4.6427e-03, 1.7638e-03, 1.3470e-03,\n",
      "         1.0734e-01, 6.9816e-04, 9.7214e-04, 4.3384e-01, 6.0449e-04, 4.9992e-04,\n",
      "         1.6917e-03, 2.7069e-03, 5.0370e-04, 1.8429e-01, 4.9335e-04, 8.0465e-04,\n",
      "         7.3367e-02, 6.4333e-04, 1.2034e-03, 2.0045e-02, 1.8714e-03, 3.9811e-04,\n",
      "         3.2715e-02, 3.6509e-04, 3.7187e-04],\n",
      "        [1.1235e-01, 8.0378e-04, 1.8099e-03, 6.4730e-03, 2.8880e-03, 2.1052e-03,\n",
      "         9.1646e-02, 1.1724e-03, 1.6707e-03, 3.9958e-01, 1.0851e-03, 8.6469e-04,\n",
      "         2.6562e-03, 4.2943e-03, 8.8101e-04, 2.1302e-01, 9.5263e-04, 1.3790e-03,\n",
      "         8.4145e-02, 1.0922e-03, 1.9038e-03, 2.2645e-02, 2.8264e-03, 6.9688e-04,\n",
      "         3.9699e-02, 6.8967e-04, 6.7210e-04],\n",
      "        [1.1260e-01, 1.1699e-03, 2.5312e-03, 8.3391e-03, 3.7783e-03, 2.9706e-03,\n",
      "         9.2949e-02, 1.6636e-03, 2.3443e-03, 3.5444e-01, 1.6467e-03, 1.3179e-03,\n",
      "         3.6398e-03, 5.5848e-03, 1.2889e-03, 2.2443e-01, 1.4402e-03, 1.9768e-03,\n",
      "         9.5774e-02, 1.6065e-03, 2.6803e-03, 2.6888e-02, 3.7775e-03, 1.0038e-03,\n",
      "         4.2165e-02, 1.0213e-03, 9.6495e-04],\n",
      "        [1.1221e-01, 1.7408e-03, 3.3868e-03, 1.0229e-02, 4.7157e-03, 4.2431e-03,\n",
      "         1.0290e-01, 2.3665e-03, 3.1104e-03, 3.4541e-01, 2.4974e-03, 2.0525e-03,\n",
      "         5.1286e-03, 7.1544e-03, 1.9358e-03, 2.0380e-01, 2.2273e-03, 2.8557e-03,\n",
      "         9.3146e-02, 2.5227e-03, 3.5068e-03, 3.2528e-02, 5.2765e-03, 1.5485e-03,\n",
      "         4.0372e-02, 1.5698e-03, 1.5621e-03],\n",
      "        [1.1322e-01, 9.7497e-04, 2.0095e-03, 7.1723e-03, 2.9381e-03, 2.4864e-03,\n",
      "         1.0565e-01, 1.3593e-03, 1.8539e-03, 3.9398e-01, 1.2893e-03, 1.0855e-03,\n",
      "         3.0577e-03, 4.7443e-03, 1.0529e-03, 2.0116e-01, 1.1537e-03, 1.5973e-03,\n",
      "         8.2652e-02, 1.3725e-03, 2.1294e-03, 2.5836e-02, 3.4238e-03, 8.2815e-04,\n",
      "         3.5324e-02, 8.2580e-04, 8.2353e-04],\n",
      "        [1.1215e-01, 1.2260e-03, 2.4656e-03, 8.1294e-03, 3.6315e-03, 3.0624e-03,\n",
      "         1.0284e-01, 1.6714e-03, 2.2351e-03, 3.9278e-01, 1.6529e-03, 1.3641e-03,\n",
      "         3.7805e-03, 5.5725e-03, 1.3467e-03, 1.9398e-01, 1.4929e-03, 2.0026e-03,\n",
      "         8.1961e-02, 1.7507e-03, 2.5345e-03, 2.7377e-02, 4.0378e-03, 1.0958e-03,\n",
      "         3.7675e-02, 1.0730e-03, 1.1089e-03],\n",
      "        [1.2526e-01, 4.7695e-04, 1.0841e-03, 4.6427e-03, 1.7638e-03, 1.3470e-03,\n",
      "         1.0734e-01, 6.9816e-04, 9.7214e-04, 4.3384e-01, 6.0449e-04, 4.9992e-04,\n",
      "         1.6917e-03, 2.7069e-03, 5.0370e-04, 1.8429e-01, 4.9335e-04, 8.0465e-04,\n",
      "         7.3367e-02, 6.4333e-04, 1.2034e-03, 2.0045e-02, 1.8714e-03, 3.9811e-04,\n",
      "         3.2715e-02, 3.6509e-04, 3.7187e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2541e-01, 4.6837e-04, 1.0574e-03, 4.5318e-03, 1.7117e-03, 1.3125e-03,\n",
      "         1.0858e-01, 6.8311e-04, 9.4875e-04, 4.3633e-01, 5.8798e-04, 4.8848e-04,\n",
      "         1.6580e-03, 2.6760e-03, 4.9233e-04, 1.8822e-01, 4.8202e-04, 7.8670e-04,\n",
      "         6.7084e-02, 6.2986e-04, 1.1739e-03, 1.9205e-02, 1.8364e-03, 3.9168e-04,\n",
      "         3.2523e-02, 3.5599e-04, 3.6483e-04],\n",
      "        [1.2541e-01, 4.6837e-04, 1.0574e-03, 4.5318e-03, 1.7117e-03, 1.3125e-03,\n",
      "         1.0858e-01, 6.8311e-04, 9.4875e-04, 4.3633e-01, 5.8798e-04, 4.8848e-04,\n",
      "         1.6580e-03, 2.6760e-03, 4.9233e-04, 1.8822e-01, 4.8202e-04, 7.8670e-04,\n",
      "         6.7084e-02, 6.2986e-04, 1.1739e-03, 1.9205e-02, 1.8364e-03, 3.9168e-04,\n",
      "         3.2523e-02, 3.5599e-04, 3.6483e-04],\n",
      "        [1.1288e-01, 1.1554e-03, 2.4818e-03, 8.1844e-03, 3.6913e-03, 2.9116e-03,\n",
      "         9.4104e-02, 1.6355e-03, 2.3023e-03, 3.5670e-01, 1.6112e-03, 1.2943e-03,\n",
      "         3.5797e-03, 5.5381e-03, 1.2661e-03, 2.2951e-01, 1.4139e-03, 1.9444e-03,\n",
      "         8.8871e-02, 1.5810e-03, 2.6281e-03, 2.5985e-02, 3.7290e-03, 9.9307e-04,\n",
      "         4.2051e-02, 1.0026e-03, 9.5223e-04],\n",
      "        [1.1223e-01, 1.2066e-03, 2.4127e-03, 7.9652e-03, 3.5397e-03, 2.9950e-03,\n",
      "         1.0399e-01, 1.6412e-03, 2.1905e-03, 3.9551e-01, 1.6157e-03, 1.3375e-03,\n",
      "         3.7161e-03, 5.5257e-03, 1.3213e-03, 1.9793e-01, 1.4637e-03, 1.9651e-03,\n",
      "         7.6139e-02, 1.7199e-03, 2.4814e-03, 2.6390e-02, 3.9747e-03, 1.0815e-03,\n",
      "         3.7518e-02, 1.0510e-03, 1.0913e-03],\n",
      "        [1.1245e-01, 1.7173e-03, 3.3225e-03, 1.0047e-02, 4.6086e-03, 4.1582e-03,\n",
      "         1.0419e-01, 2.3296e-03, 3.0558e-03, 3.4796e-01, 2.4473e-03, 2.0170e-03,\n",
      "         5.0527e-03, 7.1078e-03, 1.9038e-03, 2.0807e-01, 2.1893e-03, 2.8076e-03,\n",
      "         8.7085e-02, 2.4837e-03, 3.4426e-03, 3.1451e-02, 5.2034e-03, 1.5317e-03,\n",
      "         4.0291e-02, 1.5408e-03, 1.5405e-03],\n",
      "        [1.1248e-01, 7.9201e-04, 1.7700e-03, 6.3354e-03, 2.8139e-03, 2.0581e-03,\n",
      "         9.2664e-02, 1.1494e-03, 1.6363e-03, 4.0205e-01, 1.0584e-03, 8.4706e-04,\n",
      "         2.6064e-03, 4.2509e-03, 8.6316e-04, 2.1773e-01, 9.3236e-04, 1.3536e-03,\n",
      "         7.7547e-02, 1.0718e-03, 1.8614e-03, 2.1810e-02, 2.7848e-03, 6.8769e-04,\n",
      "         3.9506e-02, 6.7546e-04, 6.6190e-04],\n",
      "        [1.2716e-01, 6.8779e-04, 1.4827e-03, 5.8534e-03, 2.2741e-03, 1.8711e-03,\n",
      "         1.1071e-01, 9.8391e-04, 1.3491e-03, 3.9317e-01, 9.0967e-04, 7.4757e-04,\n",
      "         2.2957e-03, 3.5557e-03, 7.3197e-04, 2.0212e-01, 7.3635e-04, 1.1490e-03,\n",
      "         7.7200e-02, 9.3961e-04, 1.6634e-03, 2.3089e-02, 2.4718e-03, 5.7167e-04,\n",
      "         3.5199e-02, 5.3530e-04, 5.3309e-04],\n",
      "        [1.0858e-01, 2.0395e-03, 3.9368e-03, 1.0891e-02, 5.4680e-03, 4.8262e-03,\n",
      "         9.1893e-02, 2.6771e-03, 3.7415e-03, 3.3517e-01, 2.9258e-03, 2.3496e-03,\n",
      "         5.8135e-03, 8.2944e-03, 2.3130e-03, 2.2026e-01, 2.7185e-03, 3.3301e-03,\n",
      "         9.0338e-02, 2.9365e-03, 4.0099e-03, 3.1206e-02, 5.7521e-03, 1.8010e-03,\n",
      "         4.3033e-02, 1.8700e-03, 1.8345e-03],\n",
      "        [1.1334e-01, 9.5945e-04, 1.9652e-03, 7.0230e-03, 2.8617e-03, 2.4306e-03,\n",
      "         1.0683e-01, 1.3342e-03, 1.8155e-03, 3.9645e-01, 1.2595e-03, 1.0637e-03,\n",
      "         3.0034e-03, 4.7020e-03, 1.0325e-03, 2.0545e-01, 1.1305e-03, 1.5665e-03,\n",
      "         7.6495e-02, 1.3478e-03, 2.0835e-03, 2.4877e-02, 3.3682e-03, 8.1698e-04,\n",
      "         3.5169e-02, 8.0845e-04, 8.1010e-04],\n",
      "        [1.1875e-01, 6.5913e-04, 1.4551e-03, 5.7103e-03, 2.2894e-03, 1.7411e-03,\n",
      "         1.0805e-01, 9.6669e-04, 1.3058e-03, 4.1056e-01, 8.5493e-04, 7.0594e-04,\n",
      "         2.2064e-03, 3.5222e-03, 7.0118e-04, 1.9995e-01, 7.2546e-04, 1.1044e-03,\n",
      "         7.3568e-02, 8.8894e-04, 1.5779e-03, 2.2163e-02, 2.4629e-03, 5.6850e-04,\n",
      "         3.6445e-02, 5.3387e-04, 5.3925e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.1359e-01, 7.8253e-04, 1.7341e-03, 6.2164e-03, 2.7477e-03, 2.0200e-03,\n",
      "         9.4024e-02, 1.1305e-03, 1.6055e-03, 4.0208e-01, 1.0344e-03, 8.3271e-04,\n",
      "         2.5622e-03, 4.2137e-03, 8.4783e-04, 2.2235e-01, 9.1424e-04, 1.3309e-03,\n",
      "         7.1919e-02, 1.0539e-03, 1.8260e-03, 2.1098e-02, 2.7477e-03, 6.7958e-04,\n",
      "         3.9343e-02, 6.6232e-04, 6.5296e-04],\n",
      "        [1.2682e-01, 4.6151e-04, 1.0338e-03, 4.4370e-03, 1.6655e-03, 1.2844e-03,\n",
      "         1.1028e-01, 6.7069e-04, 9.2803e-04, 4.3596e-01, 5.7320e-04, 4.7927e-04,\n",
      "         1.6287e-03, 2.6494e-03, 4.8256e-04, 1.9210e-01, 4.7184e-04, 7.7070e-04,\n",
      "         6.1773e-02, 6.1800e-04, 1.1495e-03, 1.8496e-02, 1.8058e-03, 3.8594e-04,\n",
      "         3.2364e-02, 3.4765e-04, 3.5866e-04],\n",
      "        [1.1998e-01, 6.5016e-04, 1.4250e-03, 5.6021e-03, 2.2307e-03, 1.7064e-03,\n",
      "         1.0974e-01, 9.5006e-04, 1.2787e-03, 4.1055e-01, 8.3446e-04, 6.9328e-04,\n",
      "         2.1693e-03, 3.4892e-03, 6.8795e-04, 2.0398e-01, 7.1127e-04, 1.0830e-03,\n",
      "         6.8100e-02, 8.7337e-04, 1.5474e-03, 2.1392e-02, 2.4246e-03, 5.6085e-04,\n",
      "         3.6288e-02, 5.2205e-04, 5.3055e-04],\n",
      "        [1.1349e-01, 1.6982e-03, 3.2637e-03, 9.8870e-03, 4.5123e-03, 4.0885e-03,\n",
      "         1.0572e-01, 2.2990e-03, 3.0064e-03, 3.4841e-01, 2.4018e-03, 1.9881e-03,\n",
      "         4.9837e-03, 7.0676e-03, 1.8758e-03, 2.1229e-01, 2.1543e-03, 2.7645e-03,\n",
      "         8.1826e-02, 2.4484e-03, 3.3881e-03, 3.0528e-02, 5.1389e-03, 1.5162e-03,\n",
      "         4.0221e-02, 1.5141e-03, 1.5215e-03],\n",
      "        [1.1404e-01, 1.1426e-03, 2.4361e-03, 8.0473e-03, 3.6100e-03, 2.8625e-03,\n",
      "         9.5586e-02, 1.6132e-03, 2.2623e-03, 3.5685e-01, 1.5797e-03, 1.2750e-03,\n",
      "         3.5276e-03, 5.5007e-03, 1.2466e-03, 2.3433e-01, 1.3907e-03, 1.9137e-03,\n",
      "         8.2914e-02, 1.5587e-03, 2.5844e-03, 2.5185e-02, 3.6807e-03, 9.8310e-04,\n",
      "         4.1959e-02, 9.8434e-04, 9.4022e-04],\n",
      "        [1.0951e-01, 2.0201e-03, 3.8740e-03, 1.0734e-02, 5.3649e-03, 4.7532e-03,\n",
      "         9.3189e-02, 2.6471e-03, 3.6862e-03, 3.3581e-01, 2.8773e-03, 2.3198e-03,\n",
      "         5.7447e-03, 8.2541e-03, 2.2815e-03, 2.2470e-01, 2.6821e-03, 3.2841e-03,\n",
      "         8.5015e-02, 2.9019e-03, 3.9499e-03, 3.0302e-02, 5.6858e-03, 1.7874e-03,\n",
      "         4.2965e-02, 1.8404e-03, 1.8154e-03],\n",
      "        [1.2682e-01, 4.6151e-04, 1.0338e-03, 4.4370e-03, 1.6655e-03, 1.2844e-03,\n",
      "         1.1028e-01, 6.7069e-04, 9.2803e-04, 4.3596e-01, 5.7320e-04, 4.7927e-04,\n",
      "         1.6287e-03, 2.6494e-03, 4.8256e-04, 1.9210e-01, 4.7184e-04, 7.7070e-04,\n",
      "         6.1773e-02, 6.1800e-04, 1.1495e-03, 1.8496e-02, 1.8058e-03, 3.8594e-04,\n",
      "         3.2364e-02, 3.4765e-04, 3.5866e-04],\n",
      "        [1.1441e-01, 9.4701e-04, 1.9253e-03, 6.8935e-03, 2.7940e-03, 2.3853e-03,\n",
      "         1.0837e-01, 1.3136e-03, 1.7814e-03, 3.9645e-01, 1.2329e-03, 1.0462e-03,\n",
      "         2.9549e-03, 4.6658e-03, 1.0151e-03, 2.0975e-01, 1.1096e-03, 1.5393e-03,\n",
      "         7.1225e-02, 1.3261e-03, 2.0450e-03, 2.4067e-02, 3.3198e-03, 8.0706e-04,\n",
      "         3.5039e-02, 7.9272e-04, 7.9850e-04],\n",
      "        [1.1322e-01, 1.1912e-03, 2.3654e-03, 7.8234e-03, 3.4585e-03, 2.9407e-03,\n",
      "         1.0546e-01, 1.6165e-03, 2.1510e-03, 3.9586e-01, 1.5826e-03, 1.3162e-03,\n",
      "         3.6591e-03, 5.4862e-03, 1.2999e-03, 2.0189e-01, 1.4374e-03, 1.9321e-03,\n",
      "         7.1144e-02, 1.6928e-03, 2.4372e-03, 2.5556e-02, 3.9200e-03, 1.0688e-03,\n",
      "         3.7384e-02, 1.0312e-03, 1.0761e-03],\n",
      "        [1.2855e-01, 6.7880e-04, 1.4526e-03, 5.7442e-03, 2.2168e-03, 1.8347e-03,\n",
      "         1.1249e-01, 9.6765e-04, 1.3218e-03, 3.9300e-01, 8.8861e-04, 7.3462e-04,\n",
      "         2.2584e-03, 3.5235e-03, 7.1847e-04, 2.0635e-01, 7.2233e-04, 1.1274e-03,\n",
      "         7.1466e-02, 9.2381e-04, 1.6320e-03, 2.2287e-02, 2.4342e-03, 5.6430e-04,\n",
      "         3.5063e-02, 5.2372e-04, 5.2471e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1111, 0.0016, 0.0031, 0.0094, 0.0043, 0.0038, 0.0958, 0.0021, 0.0030,\n",
      "         0.3417, 0.0022, 0.0018, 0.0046, 0.0070, 0.0017, 0.2408, 0.0021, 0.0026,\n",
      "         0.0800, 0.0023, 0.0032, 0.0272, 0.0047, 0.0013, 0.0401, 0.0014, 0.0013]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2941e-01, 4.5615e-04, 1.0129e-03, 4.3567e-03, 1.6246e-03, 1.2620e-03,\n",
      "         1.1241e-01, 6.6068e-04, 9.0971e-04, 4.3301e-01, 5.6005e-04, 4.7205e-04,\n",
      "         1.6033e-03, 2.6271e-03, 4.7427e-04, 1.9594e-01, 4.6276e-04, 7.5643e-04,\n",
      "         5.7265e-02, 6.0763e-04, 1.1296e-03, 1.7897e-02, 1.7790e-03, 3.8081e-04,\n",
      "         3.2238e-02, 3.4000e-04, 3.5326e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2802e-01, 4.6797e-04, 1.0167e-03, 4.3843e-03, 1.6854e-03, 1.2805e-03,\n",
      "         1.1168e-01, 6.6038e-04, 9.2360e-04, 4.4327e-01, 5.7589e-04, 4.6172e-04,\n",
      "         1.6453e-03, 2.6458e-03, 4.7192e-04, 1.8910e-01, 4.6060e-04, 7.7402e-04,\n",
      "         5.5802e-02, 6.2031e-04, 1.1612e-03, 1.7286e-02, 1.7726e-03, 3.9899e-04,\n",
      "         3.2709e-02, 3.5177e-04, 3.6524e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1227, 0.0006, 0.0012, 0.0049, 0.0021, 0.0015, 0.0965, 0.0008, 0.0012,\n",
      "         0.4353, 0.0007, 0.0006, 0.0020, 0.0032, 0.0006, 0.2062, 0.0006, 0.0010,\n",
      "         0.0597, 0.0007, 0.0014, 0.0174, 0.0020, 0.0005, 0.0357, 0.0005, 0.0005]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1239, 0.0008, 0.0017, 0.0063, 0.0028, 0.0022, 0.0984, 0.0011, 0.0017,\n",
      "         0.3915, 0.0011, 0.0009, 0.0027, 0.0043, 0.0009, 0.2207, 0.0009, 0.0014,\n",
      "         0.0692, 0.0011, 0.0019, 0.0210, 0.0027, 0.0007, 0.0386, 0.0007, 0.0007]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2941e-01, 4.5615e-04, 1.0129e-03, 4.3567e-03, 1.6246e-03, 1.2620e-03,\n",
      "         1.1241e-01, 6.6068e-04, 9.0971e-04, 4.3301e-01, 5.6005e-04, 4.7205e-04,\n",
      "         1.6033e-03, 2.6271e-03, 4.7427e-04, 1.9594e-01, 4.6276e-04, 7.5643e-04,\n",
      "         5.7265e-02, 6.0763e-04, 1.1296e-03, 1.7897e-02, 1.7790e-03, 3.8081e-04,\n",
      "         3.2238e-02, 3.4000e-04, 3.5326e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1310, 0.0007, 0.0014, 0.0057, 0.0022, 0.0018, 0.1146, 0.0010, 0.0013,\n",
      "         0.3905, 0.0009, 0.0007, 0.0022, 0.0035, 0.0007, 0.2104, 0.0007, 0.0011,\n",
      "         0.0665, 0.0009, 0.0016, 0.0216, 0.0024, 0.0006, 0.0349, 0.0005, 0.0005]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1225, 0.0009, 0.0020, 0.0071, 0.0029, 0.0024, 0.1134, 0.0013, 0.0018,\n",
      "         0.3641, 0.0013, 0.0011, 0.0030, 0.0046, 0.0010, 0.2215, 0.0011, 0.0016,\n",
      "         0.0737, 0.0013, 0.0022, 0.0248, 0.0032, 0.0008, 0.0390, 0.0008, 0.0008]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1241, 0.0012, 0.0024, 0.0081, 0.0034, 0.0028, 0.1172, 0.0016, 0.0021,\n",
      "         0.3475, 0.0016, 0.0013, 0.0035, 0.0053, 0.0013, 0.2202, 0.0013, 0.0019,\n",
      "         0.0726, 0.0015, 0.0027, 0.0257, 0.0038, 0.0010, 0.0441, 0.0009, 0.0010]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2941e-01, 4.5615e-04, 1.0129e-03, 4.3567e-03, 1.6246e-03, 1.2620e-03,\n",
      "         1.1241e-01, 6.6068e-04, 9.0971e-04, 4.3301e-01, 5.6005e-04, 4.7205e-04,\n",
      "         1.6033e-03, 2.6271e-03, 4.7427e-04, 1.9594e-01, 4.6276e-04, 7.5643e-04,\n",
      "         5.7265e-02, 6.0763e-04, 1.1296e-03, 1.7897e-02, 1.7790e-03, 3.8081e-04,\n",
      "         3.2238e-02, 3.4000e-04, 3.5326e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2393e-01, 8.3255e-04, 1.7422e-03, 6.2910e-03, 2.7823e-03, 2.1950e-03,\n",
      "         9.8434e-02, 1.1456e-03, 1.6602e-03, 3.9153e-01, 1.1101e-03, 8.5309e-04,\n",
      "         2.7006e-03, 4.2528e-03, 8.6476e-04, 2.2069e-01, 9.0489e-04, 1.4009e-03,\n",
      "         6.9224e-02, 1.1113e-03, 1.9427e-03, 2.1012e-02, 2.7463e-03, 7.0990e-04,\n",
      "         3.8585e-02, 6.7971e-04, 6.6371e-04],\n",
      "        [1.2408e-01, 1.1982e-03, 2.3728e-03, 8.0980e-03, 3.4355e-03, 2.7624e-03,\n",
      "         1.1718e-01, 1.6432e-03, 2.1269e-03, 3.4746e-01, 1.5538e-03, 1.3072e-03,\n",
      "         3.4637e-03, 5.3326e-03, 1.2660e-03, 2.2025e-01, 1.3239e-03, 1.8625e-03,\n",
      "         7.2611e-02, 1.5491e-03, 2.6510e-03, 2.5703e-02, 3.7945e-03, 1.0204e-03,\n",
      "         4.4056e-02, 9.4967e-04, 9.5373e-04],\n",
      "        [1.2266e-01, 5.6782e-04, 1.2390e-03, 4.8628e-03, 2.1042e-03, 1.5386e-03,\n",
      "         9.6485e-02, 7.9667e-04, 1.1739e-03, 4.3534e-01, 7.2136e-04, 5.5691e-04,\n",
      "         1.9556e-03, 3.2249e-03, 5.8477e-04, 2.0621e-01, 5.9403e-04, 9.6493e-04,\n",
      "         5.9681e-02, 7.4782e-04, 1.3757e-03, 1.7444e-02, 2.0409e-03, 4.8917e-04,\n",
      "         3.5737e-02, 4.5468e-04, 4.5469e-04],\n",
      "        [1.2941e-01, 4.5615e-04, 1.0129e-03, 4.3567e-03, 1.6246e-03, 1.2620e-03,\n",
      "         1.1241e-01, 6.6068e-04, 9.0971e-04, 4.3301e-01, 5.6005e-04, 4.7205e-04,\n",
      "         1.6033e-03, 2.6271e-03, 4.7427e-04, 1.9594e-01, 4.6276e-04, 7.5643e-04,\n",
      "         5.7265e-02, 6.0763e-04, 1.1296e-03, 1.7897e-02, 1.7790e-03, 3.8081e-04,\n",
      "         3.2238e-02, 3.4000e-04, 3.5326e-04],\n",
      "        [1.1113e-01, 1.5867e-03, 3.1019e-03, 9.3633e-03, 4.2797e-03, 3.7940e-03,\n",
      "         9.5814e-02, 2.1056e-03, 2.9724e-03, 3.4166e-01, 2.1833e-03, 1.7990e-03,\n",
      "         4.5671e-03, 6.9851e-03, 1.7481e-03, 2.4079e-01, 2.0583e-03, 2.5531e-03,\n",
      "         7.9956e-02, 2.2542e-03, 3.2281e-03, 2.7209e-02, 4.7407e-03, 1.3451e-03,\n",
      "         4.0063e-02, 1.3798e-03, 1.3335e-03],\n",
      "        [1.2941e-01, 4.5615e-04, 1.0129e-03, 4.3567e-03, 1.6246e-03, 1.2620e-03,\n",
      "         1.1241e-01, 6.6068e-04, 9.0971e-04, 4.3301e-01, 5.6005e-04, 4.7205e-04,\n",
      "         1.6033e-03, 2.6271e-03, 4.7427e-04, 1.9594e-01, 4.6276e-04, 7.5643e-04,\n",
      "         5.7265e-02, 6.0763e-04, 1.1296e-03, 1.7897e-02, 1.7790e-03, 3.8081e-04,\n",
      "         3.2238e-02, 3.4000e-04, 3.5326e-04],\n",
      "        [1.2248e-01, 9.4613e-04, 1.9619e-03, 7.1216e-03, 2.9063e-03, 2.3872e-03,\n",
      "         1.1337e-01, 1.3465e-03, 1.7880e-03, 3.6408e-01, 1.2645e-03, 1.0544e-03,\n",
      "         2.9609e-03, 4.5713e-03, 1.0053e-03, 2.2151e-01, 1.0699e-03, 1.5550e-03,\n",
      "         7.3698e-02, 1.2817e-03, 2.1677e-03, 2.4848e-02, 3.2359e-03, 8.1190e-04,\n",
      "         3.9048e-02, 7.6789e-04, 7.6386e-04],\n",
      "        [1.2802e-01, 4.6797e-04, 1.0167e-03, 4.3843e-03, 1.6854e-03, 1.2805e-03,\n",
      "         1.1168e-01, 6.6038e-04, 9.2360e-04, 4.4327e-01, 5.7589e-04, 4.6172e-04,\n",
      "         1.6453e-03, 2.6458e-03, 4.7192e-04, 1.8910e-01, 4.6060e-04, 7.7402e-04,\n",
      "         5.5802e-02, 6.2031e-04, 1.1612e-03, 1.7286e-02, 1.7726e-03, 3.9899e-04,\n",
      "         3.2709e-02, 3.5177e-04, 3.6524e-04],\n",
      "        [1.2941e-01, 4.5615e-04, 1.0129e-03, 4.3567e-03, 1.6246e-03, 1.2620e-03,\n",
      "         1.1241e-01, 6.6068e-04, 9.0971e-04, 4.3301e-01, 5.6005e-04, 4.7205e-04,\n",
      "         1.6033e-03, 2.6271e-03, 4.7427e-04, 1.9594e-01, 4.6276e-04, 7.5643e-04,\n",
      "         5.7265e-02, 6.0763e-04, 1.1296e-03, 1.7897e-02, 1.7790e-03, 3.8081e-04,\n",
      "         3.2238e-02, 3.4000e-04, 3.5326e-04],\n",
      "        [1.3101e-01, 6.7165e-04, 1.4256e-03, 5.6507e-03, 2.1652e-03, 1.8054e-03,\n",
      "         1.1464e-01, 9.5413e-04, 1.2970e-03, 3.9051e-01, 8.6938e-04, 7.2415e-04,\n",
      "         2.2253e-03, 3.4946e-03, 7.0666e-04, 2.1045e-01, 7.0963e-04, 1.1075e-03,\n",
      "         6.6545e-02, 9.0981e-04, 1.6062e-03, 2.1598e-02, 2.4003e-03, 5.5760e-04,\n",
      "         3.4944e-02, 5.1279e-04, 5.1716e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2504e-01, 1.1939e-03, 2.3468e-03, 8.0242e-03, 3.3794e-03, 2.7357e-03,\n",
      "         1.1945e-01, 1.6318e-03, 2.1027e-03, 3.4487e-01, 1.5347e-03, 1.2967e-03,\n",
      "         3.4303e-03, 5.3124e-03, 1.2542e-03, 2.2470e-01, 1.3118e-03, 1.8458e-03,\n",
      "         6.8343e-02, 1.5387e-03, 2.6262e-03, 2.5309e-02, 3.7712e-03, 1.0157e-03,\n",
      "         4.4058e-02, 9.3945e-04, 9.4699e-04],\n",
      "        [1.3077e-01, 4.5465e-04, 1.0008e-03, 4.3115e-03, 1.5958e-03, 1.2494e-03,\n",
      "         1.1490e-01, 6.5581e-04, 8.9835e-04, 4.2913e-01, 5.5241e-04, 4.6815e-04,\n",
      "         1.5866e-03, 2.6156e-03, 4.6962e-04, 2.0040e-01, 4.5808e-04, 7.4939e-04,\n",
      "         5.3336e-02, 6.0325e-04, 1.1181e-03, 1.7609e-02, 1.7677e-03, 3.7896e-04,\n",
      "         3.2234e-02, 3.3599e-04, 3.5075e-04],\n",
      "        [1.3077e-01, 4.5465e-04, 1.0008e-03, 4.3115e-03, 1.5958e-03, 1.2494e-03,\n",
      "         1.1490e-01, 6.5581e-04, 8.9835e-04, 4.2913e-01, 5.5241e-04, 4.6815e-04,\n",
      "         1.5866e-03, 2.6156e-03, 4.6962e-04, 2.0040e-01, 4.5808e-04, 7.4939e-04,\n",
      "         5.3336e-02, 6.0325e-04, 1.1181e-03, 1.7609e-02, 1.7677e-03, 3.7896e-04,\n",
      "         3.2234e-02, 3.3599e-04, 3.5075e-04],\n",
      "        [1.3226e-01, 6.6963e-04, 1.4096e-03, 5.5975e-03, 2.1284e-03, 1.7883e-03,\n",
      "         1.1708e-01, 9.4755e-04, 1.2816e-03, 3.8702e-01, 8.5835e-04, 7.1852e-04,\n",
      "         2.2029e-03, 3.4800e-03, 7.0007e-04, 2.1516e-01, 7.0304e-04, 1.0976e-03,\n",
      "         6.2232e-02, 9.0390e-04, 1.5911e-03, 2.1261e-02, 2.3858e-03, 5.5519e-04,\n",
      "         3.4949e-02, 5.0712e-04, 5.1359e-04],\n",
      "        [1.2515e-01, 8.3102e-04, 1.7250e-03, 6.2390e-03, 2.7391e-03, 2.1775e-03,\n",
      "         1.0050e-01, 1.1391e-03, 1.6427e-03, 3.8822e-01, 1.0975e-03, 8.4770e-04,\n",
      "         2.6767e-03, 4.2391e-03, 8.5792e-04, 2.2560e-01, 8.9773e-04, 1.3903e-03,\n",
      "         6.4908e-02, 1.1056e-03, 1.9269e-03, 2.0713e-02, 2.7326e-03, 7.0759e-04,\n",
      "         3.8607e-02, 6.7323e-04, 6.6000e-04],\n",
      "        [1.2943e-01, 4.6661e-04, 1.0052e-03, 4.3412e-03, 1.6572e-03, 1.2683e-03,\n",
      "         1.1411e-01, 6.5617e-04, 9.1314e-04, 4.3921e-01, 5.6889e-04, 4.5849e-04,\n",
      "         1.6291e-03, 2.6370e-03, 4.6792e-04, 1.9349e-01, 4.5625e-04, 7.6768e-04,\n",
      "         5.2064e-02, 6.1616e-04, 1.1504e-03, 1.7028e-02, 1.7625e-03, 3.9715e-04,\n",
      "         3.2732e-02, 3.4805e-04, 3.6296e-04],\n",
      "        [1.2355e-01, 9.4316e-04, 1.9407e-03, 7.0586e-03, 2.8584e-03, 2.3655e-03,\n",
      "         1.1571e-01, 1.3378e-03, 1.7678e-03, 3.6111e-01, 1.2494e-03, 1.0466e-03,\n",
      "         2.9329e-03, 4.5535e-03, 9.9618e-04, 2.2624e-01, 1.0603e-03, 1.5416e-03,\n",
      "         6.9227e-02, 1.2737e-03, 2.1485e-03, 2.4477e-02, 3.2173e-03, 8.0854e-04,\n",
      "         3.9067e-02, 7.5975e-04, 7.5865e-04],\n",
      "        [1.2395e-01, 5.6664e-04, 1.2259e-03, 4.8181e-03, 2.0702e-03, 1.5253e-03,\n",
      "         9.8582e-02, 7.9137e-04, 1.1608e-03, 4.3166e-01, 7.1240e-04, 5.5293e-04,\n",
      "         1.9366e-03, 3.2123e-03, 5.7968e-04, 2.1092e-01, 5.8872e-04, 9.5733e-04,\n",
      "         5.5732e-02, 7.4335e-04, 1.3633e-03, 1.7189e-02, 2.0305e-03, 4.8734e-04,\n",
      "         3.5749e-02, 4.5003e-04, 4.5202e-04],\n",
      "        [1.3077e-01, 4.5465e-04, 1.0008e-03, 4.3115e-03, 1.5958e-03, 1.2494e-03,\n",
      "         1.1490e-01, 6.5581e-04, 8.9835e-04, 4.2913e-01, 5.5241e-04, 4.6815e-04,\n",
      "         1.5866e-03, 2.6156e-03, 4.6962e-04, 2.0040e-01, 4.5808e-04, 7.4939e-04,\n",
      "         5.3336e-02, 6.0325e-04, 1.1181e-03, 1.7609e-02, 1.7677e-03, 3.7896e-04,\n",
      "         3.2234e-02, 3.3599e-04, 3.5075e-04],\n",
      "        [1.1186e-01, 1.5837e-03, 3.0723e-03, 9.2919e-03, 4.2215e-03, 3.7645e-03,\n",
      "         9.7536e-02, 2.0966e-03, 2.9454e-03, 3.3916e-01, 2.1635e-03, 1.7882e-03,\n",
      "         4.5290e-03, 6.9682e-03, 1.7354e-03, 2.4602e-01, 2.0452e-03, 2.5364e-03,\n",
      "         7.5554e-02, 2.2453e-03, 3.2016e-03, 2.6829e-02, 4.7169e-03, 1.3429e-03,\n",
      "         4.0092e-02, 1.3689e-03, 1.3276e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.3102e-01, 4.5653e-04, 9.9605e-04, 4.2964e-03, 1.5775e-03, 1.2452e-03,\n",
      "         1.1774e-01, 6.5558e-04, 8.9316e-04, 4.2438e-01, 5.4969e-04, 4.6728e-04,\n",
      "         1.5776e-03, 2.6144e-03, 4.6828e-04, 2.0546e-01, 4.5723e-04, 7.4873e-04,\n",
      "         4.9917e-02, 6.0406e-04, 1.1140e-03, 1.7585e-02, 1.7699e-03, 3.7996e-04,\n",
      "         3.2346e-02, 3.3521e-04, 3.5080e-04],\n",
      "        [1.2536e-01, 8.3499e-04, 1.7190e-03, 6.2252e-03, 2.7116e-03, 2.1725e-03,\n",
      "         1.0281e-01, 1.1399e-03, 1.6352e-03, 3.8395e-01, 1.0938e-03, 8.4726e-04,\n",
      "         2.6641e-03, 4.2406e-03, 8.5647e-04, 2.3108e-01, 8.9719e-04, 1.3903e-03,\n",
      "         6.1119e-02, 1.1083e-03, 1.9222e-03, 2.0693e-02, 2.7380e-03, 7.0995e-04,\n",
      "         3.8751e-02, 6.7260e-04, 6.6064e-04],\n",
      "        [1.3102e-01, 4.5653e-04, 9.9605e-04, 4.2964e-03, 1.5775e-03, 1.2452e-03,\n",
      "         1.1774e-01, 6.5558e-04, 8.9316e-04, 4.2438e-01, 5.4969e-04, 4.6728e-04,\n",
      "         1.5776e-03, 2.6144e-03, 4.6828e-04, 2.0546e-01, 4.5723e-04, 7.4873e-04,\n",
      "         4.9917e-02, 6.0406e-04, 1.1140e-03, 1.7585e-02, 1.7699e-03, 3.7996e-04,\n",
      "         3.2346e-02, 3.3521e-04, 3.5080e-04],\n",
      "        [1.2495e-01, 1.1962e-03, 2.3340e-03, 7.9922e-03, 3.3402e-03, 2.7222e-03,\n",
      "         1.2191e-01, 1.6291e-03, 2.0897e-03, 3.4153e-01, 1.5266e-03, 1.2925e-03,\n",
      "         3.4086e-03, 5.3075e-03, 1.2494e-03, 2.2963e-01, 1.3083e-03, 1.8417e-03,\n",
      "         6.4539e-02, 1.5388e-03, 2.6142e-03, 2.5221e-02, 3.7704e-03, 1.0169e-03,\n",
      "         4.4165e-02, 9.3659e-04, 9.4566e-04],\n",
      "        [1.2425e-01, 5.6912e-04, 1.2213e-03, 4.8050e-03, 2.0481e-03, 1.5213e-03,\n",
      "         1.0100e-01, 7.9199e-04, 1.1549e-03, 4.2704e-01, 7.0986e-04, 5.5247e-04,\n",
      "         1.9276e-03, 3.2141e-03, 5.7873e-04, 2.1617e-01, 5.8841e-04, 9.5702e-04,\n",
      "         5.2296e-02, 7.4515e-04, 1.3598e-03, 1.7172e-02, 2.0334e-03, 4.8894e-04,\n",
      "         3.5897e-02, 4.4926e-04, 4.5231e-04],\n",
      "        [1.2356e-01, 9.4568e-04, 1.9308e-03, 7.0345e-03, 2.8251e-03, 2.3558e-03,\n",
      "         1.1825e-01, 1.3366e-03, 1.7573e-03, 3.5737e-01, 1.2435e-03, 1.0440e-03,\n",
      "         2.9154e-03, 4.5499e-03, 9.9282e-04, 2.3149e-01, 1.0579e-03, 1.5391e-03,\n",
      "         6.5250e-02, 1.2747e-03, 2.1398e-03, 2.4413e-02, 3.2187e-03, 8.1001e-04,\n",
      "         3.9185e-02, 7.5779e-04, 7.5804e-04],\n",
      "        [1.3239e-01, 6.7209e-04, 1.4029e-03, 5.5793e-03, 2.1042e-03, 1.7818e-03,\n",
      "         1.1980e-01, 9.4706e-04, 1.2743e-03, 3.8268e-01, 8.5439e-04, 7.1712e-04,\n",
      "         2.1900e-03, 3.4780e-03, 6.9801e-04, 2.2044e-01, 7.0177e-04, 1.0963e-03,\n",
      "         5.8450e-02, 9.0504e-04, 1.5853e-03, 2.1220e-02, 2.3883e-03, 5.5655e-04,\n",
      "         3.5066e-02, 5.0598e-04, 5.1348e-04],\n",
      "        [1.1175e-01, 1.5890e-03, 3.0591e-03, 9.2660e-03, 4.1813e-03, 3.7516e-03,\n",
      "         9.9426e-02, 2.0977e-03, 2.9325e-03, 3.3579e-01, 2.1574e-03, 1.7852e-03,\n",
      "         4.5053e-03, 6.9686e-03, 1.7313e-03, 2.5165e-01, 2.0442e-03, 2.5349e-03,\n",
      "         7.1608e-02, 2.2500e-03, 3.1902e-03, 2.6755e-02, 4.7195e-03, 1.3475e-03,\n",
      "         4.0218e-02, 1.3674e-03, 1.3283e-03],\n",
      "        [1.3102e-01, 4.5653e-04, 9.9605e-04, 4.2964e-03, 1.5775e-03, 1.2452e-03,\n",
      "         1.1774e-01, 6.5558e-04, 8.9316e-04, 4.2438e-01, 5.4969e-04, 4.6728e-04,\n",
      "         1.5776e-03, 2.6144e-03, 4.6828e-04, 2.0546e-01, 4.5723e-04, 7.4873e-04,\n",
      "         4.9917e-02, 6.0406e-04, 1.1140e-03, 1.7585e-02, 1.7699e-03, 3.7996e-04,\n",
      "         3.2346e-02, 3.3521e-04, 3.5080e-04],\n",
      "        [1.2978e-01, 4.6873e-04, 1.0010e-03, 4.3286e-03, 1.6399e-03, 1.2645e-03,\n",
      "         1.1690e-01, 6.5666e-04, 9.0895e-04, 4.3425e-01, 5.6695e-04, 4.5826e-04,\n",
      "         1.6209e-03, 2.6389e-03, 4.6720e-04, 1.9847e-01, 4.5568e-04, 7.6785e-04,\n",
      "         4.8817e-02, 6.1724e-04, 1.1471e-03, 1.7025e-02, 1.7660e-03, 3.9829e-04,\n",
      "         3.2875e-02, 3.4768e-04, 3.6335e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3028e-01, 4.6142e-04, 9.9780e-04, 4.3078e-03, 1.5682e-03, 1.2481e-03,\n",
      "         1.2089e-01, 6.5957e-04, 8.9344e-04, 4.1881e-01, 5.5141e-04, 4.6916e-04,\n",
      "         1.5755e-03, 2.6228e-03, 4.6990e-04, 2.1109e-01, 4.5976e-04, 7.5376e-04,\n",
      "         4.6944e-02, 6.0950e-04, 1.1163e-03, 1.7795e-02, 1.7845e-03, 3.8348e-04,\n",
      "         3.2562e-02, 3.3731e-04, 3.5316e-04],\n",
      "        [1.2464e-01, 8.4355e-04, 1.7226e-03, 6.2445e-03, 2.6967e-03, 2.1780e-03,\n",
      "         1.0536e-01, 1.1473e-03, 1.6361e-03, 3.7887e-01, 1.0980e-03, 8.5110e-04,\n",
      "         2.6616e-03, 4.2562e-03, 8.5984e-04, 2.3707e-01, 9.0266e-04, 1.3993e-03,\n",
      "         5.7790e-02, 1.1184e-03, 1.9272e-03, 2.0914e-02, 2.7592e-03, 7.1640e-04,\n",
      "         3.9002e-02, 6.7696e-04, 6.6492e-04],\n",
      "        [1.2918e-01, 4.7396e-04, 1.0034e-03, 4.3428e-03, 1.6317e-03, 1.2683e-03,\n",
      "         1.2003e-01, 6.6135e-04, 9.1024e-04, 4.2845e-01, 5.6948e-04, 4.6070e-04,\n",
      "         1.6198e-03, 2.6504e-03, 4.6940e-04, 2.0401e-01, 4.5847e-04, 7.7376e-04,\n",
      "         4.5993e-02, 6.2301e-04, 1.1505e-03, 1.7247e-02, 1.7818e-03, 4.0209e-04,\n",
      "         3.3127e-02, 3.5026e-04, 3.6612e-04],\n",
      "        [1.3028e-01, 4.6142e-04, 9.9780e-04, 4.3078e-03, 1.5682e-03, 1.2481e-03,\n",
      "         1.2089e-01, 6.5957e-04, 8.9344e-04, 4.1881e-01, 5.5141e-04, 4.6916e-04,\n",
      "         1.5755e-03, 2.6228e-03, 4.6990e-04, 2.1109e-01, 4.5976e-04, 7.5376e-04,\n",
      "         4.6944e-02, 6.0950e-04, 1.1163e-03, 1.7795e-02, 1.7845e-03, 3.8348e-04,\n",
      "         3.2562e-02, 3.3731e-04, 3.5316e-04],\n",
      "        [1.2264e-01, 9.5308e-04, 1.9310e-03, 7.0443e-03, 2.8044e-03, 2.3566e-03,\n",
      "         1.2098e-01, 1.3420e-03, 1.7555e-03, 3.5291e-01, 1.2457e-03, 1.0462e-03,\n",
      "         2.9069e-03, 4.5587e-03, 9.9449e-04, 2.3721e-01, 1.0619e-03, 1.5461e-03,\n",
      "         6.1713e-02, 1.2836e-03, 2.1408e-03, 2.4618e-02, 3.2378e-03, 8.1580e-04,\n",
      "         3.9391e-02, 7.6126e-04, 7.6143e-04],\n",
      "        [1.3028e-01, 4.6142e-04, 9.9780e-04, 4.3078e-03, 1.5682e-03, 1.2481e-03,\n",
      "         1.2089e-01, 6.5957e-04, 8.9344e-04, 4.1881e-01, 5.5141e-04, 4.6916e-04,\n",
      "         1.5755e-03, 2.6228e-03, 4.6990e-04, 2.1109e-01, 4.5976e-04, 7.5376e-04,\n",
      "         4.6944e-02, 6.0950e-04, 1.1163e-03, 1.7795e-02, 1.7845e-03, 3.8348e-04,\n",
      "         3.2562e-02, 3.3731e-04, 3.5316e-04],\n",
      "        [1.3152e-01, 6.7853e-04, 1.4044e-03, 5.5919e-03, 2.0908e-03, 1.7846e-03,\n",
      "         1.2279e-01, 9.5198e-04, 1.2739e-03, 3.7757e-01, 8.5667e-04, 7.1946e-04,\n",
      "         2.1853e-03, 3.4871e-03, 6.9995e-04, 2.2625e-01, 7.0523e-04, 1.1026e-03,\n",
      "         5.5128e-02, 9.1249e-04, 1.5878e-03, 2.1438e-02, 2.4056e-03, 5.6126e-04,\n",
      "         3.5283e-02, 5.0881e-04, 5.1641e-04],\n",
      "        [1.1088e-01, 1.6018e-03, 3.0603e-03, 9.2809e-03, 4.1567e-03, 3.7535e-03,\n",
      "         1.0147e-01, 2.1079e-03, 2.9320e-03, 3.3163e-01, 2.1635e-03, 1.7892e-03,\n",
      "         4.4943e-03, 6.9844e-03, 1.7348e-03, 2.5764e-01, 2.0542e-03, 2.5468e-03,\n",
      "         6.8074e-02, 2.2670e-03, 3.1921e-03, 2.6948e-02, 4.7454e-03, 1.3582e-03,\n",
      "         4.0431e-02, 1.3743e-03, 1.3348e-03],\n",
      "        [1.2393e-01, 1.2045e-03, 2.3329e-03, 7.9976e-03, 3.3155e-03, 2.7204e-03,\n",
      "         1.2455e-01, 1.6343e-03, 2.0865e-03, 3.3751e-01, 1.5283e-03, 1.2940e-03,\n",
      "         3.3970e-03, 5.3161e-03, 1.2507e-03, 2.3499e-01, 1.3123e-03, 1.8486e-03,\n",
      "         6.1150e-02, 1.5482e-03, 2.6134e-03, 2.5400e-02, 3.7895e-03, 1.0233e-03,\n",
      "         4.4365e-02, 9.4021e-04, 9.4911e-04],\n",
      "        [1.2366e-01, 5.7487e-04, 1.2241e-03, 4.8199e-03, 2.0362e-03, 1.5254e-03,\n",
      "         1.0373e-01, 7.9786e-04, 1.1551e-03, 4.2158e-01, 7.1298e-04, 5.5515e-04,\n",
      "         1.9274e-03, 3.2287e-03, 5.8143e-04, 2.2194e-01, 5.9252e-04, 9.6316e-04,\n",
      "         4.9300e-02, 7.5255e-04, 1.3640e-03, 1.7364e-02, 2.0481e-03, 4.9361e-04,\n",
      "         3.6166e-02, 4.5193e-04, 4.5524e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1298, 0.0007, 0.0014, 0.0056, 0.0021, 0.0018, 0.1260, 0.0010, 0.0013,\n",
      "         0.3717, 0.0009, 0.0007, 0.0022, 0.0035, 0.0007, 0.2325, 0.0007, 0.0011,\n",
      "         0.0522, 0.0009, 0.0016, 0.0219, 0.0024, 0.0006, 0.0356, 0.0005, 0.0005]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2867e-01, 4.6898e-04, 1.0052e-03, 4.3426e-03, 1.5666e-03, 1.2575e-03,\n",
      "         1.2437e-01, 6.6742e-04, 8.9844e-04, 4.1248e-01, 5.5712e-04, 4.7349e-04,\n",
      "         1.5794e-03, 2.6398e-03, 4.7421e-04, 2.1723e-01, 4.6537e-04, 7.6383e-04,\n",
      "         4.4351e-02, 6.1916e-04, 1.1245e-03, 1.8218e-02, 1.8096e-03, 3.8929e-04,\n",
      "         3.2874e-02, 3.4197e-04, 3.5753e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1298, 0.0007, 0.0014, 0.0056, 0.0021, 0.0018, 0.1260, 0.0010, 0.0013,\n",
      "         0.3717, 0.0009, 0.0007, 0.0022, 0.0035, 0.0007, 0.2325, 0.0007, 0.0011,\n",
      "         0.0522, 0.0009, 0.0016, 0.0219, 0.0024, 0.0006, 0.0356, 0.0005, 0.0005]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2867e-01, 4.6898e-04, 1.0052e-03, 4.3426e-03, 1.5666e-03, 1.2575e-03,\n",
      "         1.2437e-01, 6.6742e-04, 8.9844e-04, 4.1248e-01, 5.5712e-04, 4.7349e-04,\n",
      "         1.5794e-03, 2.6398e-03, 4.7421e-04, 2.1723e-01, 4.6537e-04, 7.6383e-04,\n",
      "         4.4351e-02, 6.1916e-04, 1.1245e-03, 1.8218e-02, 1.8096e-03, 3.8929e-04,\n",
      "         3.2874e-02, 3.4197e-04, 3.5753e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1298, 0.0007, 0.0014, 0.0056, 0.0021, 0.0018, 0.1260, 0.0010, 0.0013,\n",
      "         0.3717, 0.0009, 0.0007, 0.0022, 0.0035, 0.0007, 0.2325, 0.0007, 0.0011,\n",
      "         0.0522, 0.0009, 0.0016, 0.0219, 0.0024, 0.0006, 0.0356, 0.0005, 0.0005]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1303, 0.0009, 0.0018, 0.0065, 0.0026, 0.0023, 0.1229, 0.0012, 0.0016,\n",
      "         0.3707, 0.0011, 0.0009, 0.0028, 0.0042, 0.0009, 0.2227, 0.0009, 0.0014,\n",
      "         0.0538, 0.0012, 0.0019, 0.0238, 0.0029, 0.0008, 0.0384, 0.0007, 0.0007]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1235, 0.0011, 0.0021, 0.0071, 0.0033, 0.0027, 0.1049, 0.0014, 0.0020,\n",
      "         0.3635, 0.0014, 0.0011, 0.0032, 0.0050, 0.0011, 0.2420, 0.0012, 0.0018,\n",
      "         0.0570, 0.0014, 0.0023, 0.0236, 0.0033, 0.0009, 0.0412, 0.0009, 0.0009]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2867e-01, 4.6898e-04, 1.0052e-03, 4.3426e-03, 1.5666e-03, 1.2575e-03,\n",
      "         1.2437e-01, 6.6742e-04, 8.9844e-04, 4.1248e-01, 5.5712e-04, 4.7349e-04,\n",
      "         1.5794e-03, 2.6398e-03, 4.7421e-04, 2.1723e-01, 4.6537e-04, 7.6383e-04,\n",
      "         4.4351e-02, 6.1916e-04, 1.1245e-03, 1.8218e-02, 1.8096e-03, 3.8929e-04,\n",
      "         3.2874e-02, 3.4197e-04, 3.5753e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1298, 0.0007, 0.0014, 0.0056, 0.0021, 0.0018, 0.1260, 0.0010, 0.0013,\n",
      "         0.3717, 0.0009, 0.0007, 0.0022, 0.0035, 0.0007, 0.2325, 0.0007, 0.0011,\n",
      "         0.0522, 0.0009, 0.0016, 0.0219, 0.0024, 0.0006, 0.0356, 0.0005, 0.0005]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1303, 0.0009, 0.0018, 0.0065, 0.0026, 0.0023, 0.1229, 0.0012, 0.0016,\n",
      "         0.3707, 0.0011, 0.0009, 0.0028, 0.0042, 0.0009, 0.2227, 0.0009, 0.0014,\n",
      "         0.0538, 0.0012, 0.0019, 0.0238, 0.0029, 0.0008, 0.0384, 0.0007, 0.0007]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2867e-01, 4.6898e-04, 1.0052e-03, 4.3426e-03, 1.5666e-03, 1.2575e-03,\n",
      "         1.2437e-01, 6.6742e-04, 8.9844e-04, 4.1248e-01, 5.5712e-04, 4.7349e-04,\n",
      "         1.5794e-03, 2.6398e-03, 4.7421e-04, 2.1723e-01, 4.6537e-04, 7.6383e-04,\n",
      "         4.4351e-02, 6.1916e-04, 1.1245e-03, 1.8218e-02, 1.8096e-03, 3.8929e-04,\n",
      "         3.2874e-02, 3.4197e-04, 3.5753e-04],\n",
      "        [1.2978e-01, 6.8846e-04, 1.4131e-03, 5.6317e-03, 2.0865e-03, 1.7953e-03,\n",
      "         1.2603e-01, 9.6183e-04, 1.2796e-03, 3.7175e-01, 8.6459e-04, 7.2510e-04,\n",
      "         2.1879e-03, 3.5064e-03, 7.0550e-04, 2.3253e-01, 7.1299e-04, 1.1155e-03,\n",
      "         5.2205e-02, 9.2567e-04, 1.5976e-03, 2.1891e-02, 2.4359e-03, 5.6898e-04,\n",
      "         3.5588e-02, 5.1514e-04, 5.2200e-04],\n",
      "        [1.3026e-01, 8.7846e-04, 1.7688e-03, 6.5145e-03, 2.6387e-03, 2.2548e-03,\n",
      "         1.2290e-01, 1.2168e-03, 1.5831e-03, 3.7073e-01, 1.1372e-03, 9.4128e-04,\n",
      "         2.7519e-03, 4.1976e-03, 9.2902e-04, 2.2273e-01, 9.3449e-04, 1.4309e-03,\n",
      "         5.3781e-02, 1.2052e-03, 1.9410e-03, 2.3766e-02, 2.9203e-03, 7.6517e-04,\n",
      "         3.8421e-02, 6.8616e-04, 7.1643e-04],\n",
      "        [1.3026e-01, 8.7846e-04, 1.7688e-03, 6.5145e-03, 2.6387e-03, 2.2548e-03,\n",
      "         1.2290e-01, 1.2168e-03, 1.5831e-03, 3.7073e-01, 1.1372e-03, 9.4128e-04,\n",
      "         2.7519e-03, 4.1976e-03, 9.2902e-04, 2.2273e-01, 9.3449e-04, 1.4309e-03,\n",
      "         5.3781e-02, 1.2052e-03, 1.9410e-03, 2.3766e-02, 2.9203e-03, 7.6517e-04,\n",
      "         3.8421e-02, 6.8616e-04, 7.1643e-04],\n",
      "        [1.2978e-01, 6.8846e-04, 1.4131e-03, 5.6317e-03, 2.0865e-03, 1.7953e-03,\n",
      "         1.2603e-01, 9.6183e-04, 1.2796e-03, 3.7175e-01, 8.6459e-04, 7.2510e-04,\n",
      "         2.1879e-03, 3.5064e-03, 7.0550e-04, 2.3253e-01, 7.1299e-04, 1.1155e-03,\n",
      "         5.2205e-02, 9.2567e-04, 1.5976e-03, 2.1891e-02, 2.4359e-03, 5.6898e-04,\n",
      "         3.5588e-02, 5.1514e-04, 5.2200e-04],\n",
      "        [1.2978e-01, 6.8846e-04, 1.4131e-03, 5.6317e-03, 2.0865e-03, 1.7953e-03,\n",
      "         1.2603e-01, 9.6183e-04, 1.2796e-03, 3.7175e-01, 8.6459e-04, 7.2510e-04,\n",
      "         2.1879e-03, 3.5064e-03, 7.0550e-04, 2.3253e-01, 7.1299e-04, 1.1155e-03,\n",
      "         5.2205e-02, 9.2567e-04, 1.5976e-03, 2.1891e-02, 2.4359e-03, 5.6898e-04,\n",
      "         3.5588e-02, 5.1514e-04, 5.2200e-04],\n",
      "        [1.2978e-01, 6.8846e-04, 1.4131e-03, 5.6317e-03, 2.0865e-03, 1.7953e-03,\n",
      "         1.2603e-01, 9.6183e-04, 1.2796e-03, 3.7175e-01, 8.6459e-04, 7.2510e-04,\n",
      "         2.1879e-03, 3.5064e-03, 7.0550e-04, 2.3253e-01, 7.1299e-04, 1.1155e-03,\n",
      "         5.2205e-02, 9.2567e-04, 1.5976e-03, 2.1891e-02, 2.4359e-03, 5.6898e-04,\n",
      "         3.5588e-02, 5.1514e-04, 5.2200e-04],\n",
      "        [1.2347e-01, 1.0521e-03, 2.1205e-03, 7.1319e-03, 3.2537e-03, 2.6765e-03,\n",
      "         1.0490e-01, 1.4388e-03, 1.9774e-03, 3.6355e-01, 1.3983e-03, 1.1214e-03,\n",
      "         3.2250e-03, 5.0328e-03, 1.1445e-03, 2.4204e-01, 1.1872e-03, 1.7521e-03,\n",
      "         5.7028e-02, 1.4450e-03, 2.2749e-03, 2.3575e-02, 3.2913e-03, 9.2855e-04,\n",
      "         4.1239e-02, 8.6984e-04, 8.7566e-04],\n",
      "        [1.2867e-01, 4.6898e-04, 1.0052e-03, 4.3426e-03, 1.5666e-03, 1.2575e-03,\n",
      "         1.2437e-01, 6.6742e-04, 8.9844e-04, 4.1248e-01, 5.5712e-04, 4.7349e-04,\n",
      "         1.5794e-03, 2.6398e-03, 4.7421e-04, 2.1723e-01, 4.6537e-04, 7.6383e-04,\n",
      "         4.4351e-02, 6.1916e-04, 1.1245e-03, 1.8218e-02, 1.8096e-03, 3.8929e-04,\n",
      "         3.2874e-02, 3.4197e-04, 3.5753e-04],\n",
      "        [1.2867e-01, 4.6898e-04, 1.0052e-03, 4.3426e-03, 1.5666e-03, 1.2575e-03,\n",
      "         1.2437e-01, 6.6742e-04, 8.9844e-04, 4.1248e-01, 5.5712e-04, 4.7349e-04,\n",
      "         1.5794e-03, 2.6398e-03, 4.7421e-04, 2.1723e-01, 4.6537e-04, 7.6383e-04,\n",
      "         4.4351e-02, 6.1916e-04, 1.1245e-03, 1.8218e-02, 1.8096e-03, 3.8929e-04,\n",
      "         3.2874e-02, 3.4197e-04, 3.5753e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2746e-01, 6.9444e-04, 1.4146e-03, 5.6441e-03, 2.0744e-03, 1.7964e-03,\n",
      "         1.2856e-01, 9.6620e-04, 1.2799e-03, 3.6690e-01, 8.6837e-04, 7.2686e-04,\n",
      "         2.1794e-03, 3.5116e-03, 7.0752e-04, 2.3928e-01, 7.1700e-04, 1.1228e-03,\n",
      "         4.9532e-02, 9.3402e-04, 1.5989e-03, 2.2227e-02, 2.4544e-03, 5.7355e-04,\n",
      "         3.5741e-02, 5.1908e-04, 5.2474e-04],\n",
      "        [1.2642e-01, 4.7345e-04, 1.0067e-03, 4.3529e-03, 1.5582e-03, 1.2590e-03,\n",
      "         1.2708e-01, 6.7087e-04, 8.9903e-04, 4.0737e-01, 5.5973e-04, 4.7485e-04,\n",
      "         1.5743e-03, 2.6447e-03, 4.7579e-04, 2.2375e-01, 4.6815e-04, 7.6956e-04,\n",
      "         4.1969e-02, 6.2511e-04, 1.1257e-03, 1.8532e-02, 1.8246e-03, 3.9266e-04,\n",
      "         3.3028e-02, 3.4475e-04, 3.5968e-04],\n",
      "        [1.2147e-01, 1.0611e-03, 2.1234e-03, 7.1468e-03, 3.2375e-03, 2.6786e-03,\n",
      "         1.0691e-01, 1.4458e-03, 1.9788e-03, 3.5905e-01, 1.4047e-03, 1.1241e-03,\n",
      "         3.2146e-03, 5.0412e-03, 1.1480e-03, 2.4861e-01, 1.1943e-03, 1.7632e-03,\n",
      "         5.4315e-02, 1.4582e-03, 2.2772e-03, 2.3914e-02, 3.3144e-03, 9.3603e-04,\n",
      "         4.1425e-02, 8.7611e-04, 8.8036e-04],\n",
      "        [1.2746e-01, 6.9444e-04, 1.4146e-03, 5.6441e-03, 2.0744e-03, 1.7964e-03,\n",
      "         1.2856e-01, 9.6620e-04, 1.2799e-03, 3.6690e-01, 8.6837e-04, 7.2686e-04,\n",
      "         2.1794e-03, 3.5116e-03, 7.0752e-04, 2.3928e-01, 7.1700e-04, 1.1228e-03,\n",
      "         4.9532e-02, 9.3402e-04, 1.5989e-03, 2.2227e-02, 2.4544e-03, 5.7355e-04,\n",
      "         3.5741e-02, 5.1908e-04, 5.2474e-04],\n",
      "        [1.2806e-01, 8.8585e-04, 1.7712e-03, 6.5293e-03, 2.6243e-03, 2.2567e-03,\n",
      "         1.2532e-01, 1.2226e-03, 1.5839e-03, 3.6630e-01, 1.1422e-03, 9.4391e-04,\n",
      "         2.7431e-03, 4.2050e-03, 9.3168e-04, 2.2895e-01, 9.3959e-04, 1.4405e-03,\n",
      "         5.1164e-02, 1.2157e-03, 1.9430e-03, 2.4120e-02, 2.9421e-03, 7.7118e-04,\n",
      "         3.8586e-02, 6.9132e-04, 7.2022e-04],\n",
      "        [1.2642e-01, 4.7345e-04, 1.0067e-03, 4.3529e-03, 1.5582e-03, 1.2590e-03,\n",
      "         1.2708e-01, 6.7087e-04, 8.9903e-04, 4.0737e-01, 5.5973e-04, 4.7485e-04,\n",
      "         1.5743e-03, 2.6447e-03, 4.7579e-04, 2.2375e-01, 4.6815e-04, 7.6956e-04,\n",
      "         4.1969e-02, 6.2511e-04, 1.1257e-03, 1.8532e-02, 1.8246e-03, 3.9266e-04,\n",
      "         3.3028e-02, 3.4475e-04, 3.5968e-04],\n",
      "        [1.2806e-01, 8.8585e-04, 1.7712e-03, 6.5293e-03, 2.6243e-03, 2.2567e-03,\n",
      "         1.2532e-01, 1.2226e-03, 1.5839e-03, 3.6630e-01, 1.1422e-03, 9.4391e-04,\n",
      "         2.7431e-03, 4.2050e-03, 9.3168e-04, 2.2895e-01, 9.3959e-04, 1.4405e-03,\n",
      "         5.1164e-02, 1.2157e-03, 1.9430e-03, 2.4120e-02, 2.9421e-03, 7.7118e-04,\n",
      "         3.8586e-02, 6.9132e-04, 7.2022e-04],\n",
      "        [1.2642e-01, 4.7345e-04, 1.0067e-03, 4.3529e-03, 1.5582e-03, 1.2590e-03,\n",
      "         1.2708e-01, 6.7087e-04, 8.9903e-04, 4.0737e-01, 5.5973e-04, 4.7485e-04,\n",
      "         1.5743e-03, 2.6447e-03, 4.7579e-04, 2.2375e-01, 4.6815e-04, 7.6956e-04,\n",
      "         4.1969e-02, 6.2511e-04, 1.1257e-03, 1.8532e-02, 1.8246e-03, 3.9266e-04,\n",
      "         3.3028e-02, 3.4475e-04, 3.5968e-04],\n",
      "        [1.2746e-01, 6.9444e-04, 1.4146e-03, 5.6441e-03, 2.0744e-03, 1.7964e-03,\n",
      "         1.2856e-01, 9.6620e-04, 1.2799e-03, 3.6690e-01, 8.6837e-04, 7.2686e-04,\n",
      "         2.1794e-03, 3.5116e-03, 7.0752e-04, 2.3928e-01, 7.1700e-04, 1.1228e-03,\n",
      "         4.9532e-02, 9.3402e-04, 1.5989e-03, 2.2227e-02, 2.4544e-03, 5.7355e-04,\n",
      "         3.5741e-02, 5.1908e-04, 5.2474e-04],\n",
      "        [1.2746e-01, 6.9444e-04, 1.4146e-03, 5.6441e-03, 2.0744e-03, 1.7964e-03,\n",
      "         1.2856e-01, 9.6620e-04, 1.2799e-03, 3.6690e-01, 8.6837e-04, 7.2686e-04,\n",
      "         2.1794e-03, 3.5116e-03, 7.0752e-04, 2.3928e-01, 7.1700e-04, 1.1228e-03,\n",
      "         4.9532e-02, 9.3402e-04, 1.5989e-03, 2.2227e-02, 2.4544e-03, 5.7355e-04,\n",
      "         3.5741e-02, 5.1908e-04, 5.2474e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2465e-01, 6.9676e-04, 1.4095e-03, 5.6315e-03, 2.0554e-03, 1.7887e-03,\n",
      "         1.3041e-01, 9.6551e-04, 1.2753e-03, 3.6287e-01, 8.6834e-04, 7.2509e-04,\n",
      "         2.1610e-03, 3.5041e-03, 7.0630e-04, 2.4655e-01, 7.1756e-04, 1.1251e-03,\n",
      "         4.7076e-02, 9.3787e-04, 1.5924e-03, 2.2456e-02, 2.4618e-03, 5.7520e-04,\n",
      "         3.5756e-02, 5.2079e-04, 5.2484e-04],\n",
      "        [1.2362e-01, 4.7463e-04, 1.0024e-03, 4.3393e-03, 1.5428e-03, 1.2528e-03,\n",
      "         1.2911e-01, 6.7059e-04, 8.9501e-04, 4.0334e-01, 5.5963e-04, 4.7343e-04,\n",
      "         1.5617e-03, 2.6398e-03, 4.7498e-04, 2.3059e-01, 4.6851e-04, 7.7072e-04,\n",
      "         3.9765e-02, 6.2770e-04, 1.1206e-03, 1.8727e-02, 1.8281e-03, 3.9365e-04,\n",
      "         3.3046e-02, 3.4548e-04, 3.5952e-04],\n",
      "        [1.2465e-01, 6.9676e-04, 1.4095e-03, 5.6315e-03, 2.0554e-03, 1.7887e-03,\n",
      "         1.3041e-01, 9.6551e-04, 1.2753e-03, 3.6287e-01, 8.6834e-04, 7.2509e-04,\n",
      "         2.1610e-03, 3.5041e-03, 7.0630e-04, 2.4655e-01, 7.1756e-04, 1.1251e-03,\n",
      "         4.7076e-02, 9.3787e-04, 1.5924e-03, 2.2456e-02, 2.4618e-03, 5.7520e-04,\n",
      "         3.5756e-02, 5.2079e-04, 5.2484e-04],\n",
      "        [1.2541e-01, 8.8886e-04, 1.7657e-03, 6.5173e-03, 2.6017e-03, 2.2484e-03,\n",
      "         1.2713e-01, 1.2225e-03, 1.5790e-03, 3.6266e-01, 1.1425e-03, 9.4220e-04,\n",
      "         2.7227e-03, 4.1982e-03, 9.3035e-04, 2.3562e-01, 9.4045e-04, 1.4439e-03,\n",
      "         4.8755e-02, 1.2208e-03, 1.9362e-03, 2.4363e-02, 2.9517e-03, 7.7354e-04,\n",
      "         3.8615e-02, 6.9368e-04, 7.2065e-04],\n",
      "        [1.2362e-01, 4.7463e-04, 1.0024e-03, 4.3393e-03, 1.5428e-03, 1.2528e-03,\n",
      "         1.2911e-01, 6.7059e-04, 8.9501e-04, 4.0334e-01, 5.5963e-04, 4.7343e-04,\n",
      "         1.5617e-03, 2.6398e-03, 4.7498e-04, 2.3059e-01, 4.6851e-04, 7.7072e-04,\n",
      "         3.9765e-02, 6.2770e-04, 1.1206e-03, 1.8727e-02, 1.8281e-03, 3.9365e-04,\n",
      "         3.3046e-02, 3.4548e-04, 3.5952e-04],\n",
      "        [1.2362e-01, 4.7463e-04, 1.0024e-03, 4.3393e-03, 1.5428e-03, 1.2528e-03,\n",
      "         1.2911e-01, 6.7059e-04, 8.9501e-04, 4.0334e-01, 5.5963e-04, 4.7343e-04,\n",
      "         1.5617e-03, 2.6398e-03, 4.7498e-04, 2.3059e-01, 4.6851e-04, 7.7072e-04,\n",
      "         3.9765e-02, 6.2770e-04, 1.1206e-03, 1.8727e-02, 1.8281e-03, 3.9365e-04,\n",
      "         3.3046e-02, 3.4548e-04, 3.5952e-04],\n",
      "        [1.1905e-01, 1.0649e-03, 2.1171e-03, 7.1329e-03, 3.2112e-03, 2.6685e-03,\n",
      "         1.0842e-01, 1.4458e-03, 1.9732e-03, 3.5523e-01, 1.4053e-03, 1.1217e-03,\n",
      "         3.1908e-03, 5.0323e-03, 1.1467e-03, 2.5564e-01, 1.1963e-03, 1.7665e-03,\n",
      "         5.1815e-02, 1.4650e-03, 2.2695e-03, 2.4146e-02, 3.3235e-03, 9.3912e-04,\n",
      "         4.1469e-02, 8.7869e-04, 8.8087e-04],\n",
      "        [1.2465e-01, 6.9676e-04, 1.4095e-03, 5.6315e-03, 2.0554e-03, 1.7887e-03,\n",
      "         1.3041e-01, 9.6551e-04, 1.2753e-03, 3.6287e-01, 8.6834e-04, 7.2509e-04,\n",
      "         2.1610e-03, 3.5041e-03, 7.0630e-04, 2.4655e-01, 7.1756e-04, 1.1251e-03,\n",
      "         4.7076e-02, 9.3787e-04, 1.5924e-03, 2.2456e-02, 2.4618e-03, 5.7520e-04,\n",
      "         3.5756e-02, 5.2079e-04, 5.2484e-04],\n",
      "        [1.2541e-01, 8.8886e-04, 1.7657e-03, 6.5173e-03, 2.6017e-03, 2.2484e-03,\n",
      "         1.2713e-01, 1.2225e-03, 1.5790e-03, 3.6266e-01, 1.1425e-03, 9.4220e-04,\n",
      "         2.7227e-03, 4.1982e-03, 9.3035e-04, 2.3562e-01, 9.4045e-04, 1.4439e-03,\n",
      "         4.8755e-02, 1.2208e-03, 1.9362e-03, 2.4363e-02, 2.9517e-03, 7.7354e-04,\n",
      "         3.8615e-02, 6.9368e-04, 7.2065e-04],\n",
      "        [1.2465e-01, 6.9676e-04, 1.4095e-03, 5.6315e-03, 2.0554e-03, 1.7887e-03,\n",
      "         1.3041e-01, 9.6551e-04, 1.2753e-03, 3.6287e-01, 8.6834e-04, 7.2509e-04,\n",
      "         2.1610e-03, 3.5041e-03, 7.0630e-04, 2.4655e-01, 7.1756e-04, 1.1251e-03,\n",
      "         4.7076e-02, 9.3787e-04, 1.5924e-03, 2.2456e-02, 2.4618e-03, 5.7520e-04,\n",
      "         3.5756e-02, 5.2079e-04, 5.2484e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1.2036e-01, 4.7273e-04, 9.9296e-04, 4.3044e-03, 1.5208e-03, 1.2396e-03,\n",
      "         1.3049e-01, 6.6692e-04, 8.8675e-04, 4.0024e-01, 5.5709e-04, 4.6951e-04,\n",
      "         1.5423e-03, 2.6262e-03, 4.7202e-04, 2.3781e-01, 4.6671e-04, 7.6763e-04,\n",
      "         3.7714e-02, 6.2722e-04, 1.1098e-03, 1.8809e-02, 1.8207e-03, 3.9244e-04,\n",
      "         3.2941e-02, 3.4431e-04, 3.5727e-04],\n",
      "        [1.2239e-01, 8.8820e-04, 1.7533e-03, 6.4817e-03, 2.5725e-03, 2.2312e-03,\n",
      "         1.2834e-01, 1.2167e-03, 1.5694e-03, 3.5963e-01, 1.1384e-03, 9.3659e-04,\n",
      "         2.6916e-03, 4.1776e-03, 9.2526e-04, 2.4284e-01, 9.3726e-04, 1.4421e-03,\n",
      "         4.6530e-02, 1.2206e-03, 1.9215e-03, 2.4511e-02, 2.9515e-03, 7.7259e-04,\n",
      "         3.8516e-02, 6.9371e-04, 7.1821e-04],\n",
      "        [1.2143e-01, 6.9474e-04, 1.3977e-03, 5.5937e-03, 2.0280e-03, 1.7718e-03,\n",
      "         1.3170e-01, 9.6083e-04, 1.2649e-03, 3.5961e-01, 8.6518e-04, 7.1996e-04,\n",
      "         2.1349e-03, 3.4875e-03, 7.0238e-04, 2.5422e-01, 7.1540e-04, 1.1214e-03,\n",
      "         4.4794e-02, 9.3779e-04, 1.5791e-03, 2.2555e-02, 2.4547e-03, 5.7389e-04,\n",
      "         3.5655e-02, 5.1975e-04, 5.2197e-04],\n",
      "        [1.2036e-01, 4.7273e-04, 9.9296e-04, 4.3044e-03, 1.5208e-03, 1.2396e-03,\n",
      "         1.3049e-01, 6.6692e-04, 8.8675e-04, 4.0024e-01, 5.5709e-04, 4.6951e-04,\n",
      "         1.5423e-03, 2.6262e-03, 4.7202e-04, 2.3781e-01, 4.6671e-04, 7.6763e-04,\n",
      "         3.7714e-02, 6.2722e-04, 1.1098e-03, 1.8809e-02, 1.8207e-03, 3.9244e-04,\n",
      "         3.2941e-02, 3.4431e-04, 3.5727e-04],\n",
      "        [1.2239e-01, 8.8820e-04, 1.7533e-03, 6.4817e-03, 2.5725e-03, 2.2312e-03,\n",
      "         1.2834e-01, 1.2167e-03, 1.5694e-03, 3.5963e-01, 1.1384e-03, 9.3659e-04,\n",
      "         2.6916e-03, 4.1776e-03, 9.2526e-04, 2.4284e-01, 9.3726e-04, 1.4421e-03,\n",
      "         4.6530e-02, 1.2206e-03, 1.9215e-03, 2.4511e-02, 2.9515e-03, 7.7259e-04,\n",
      "         3.8516e-02, 6.9371e-04, 7.1821e-04],\n",
      "        [1.2036e-01, 4.7273e-04, 9.9296e-04, 4.3044e-03, 1.5208e-03, 1.2396e-03,\n",
      "         1.3049e-01, 6.6692e-04, 8.8675e-04, 4.0024e-01, 5.5709e-04, 4.6951e-04,\n",
      "         1.5423e-03, 2.6262e-03, 4.7202e-04, 2.3781e-01, 4.6671e-04, 7.6763e-04,\n",
      "         3.7714e-02, 6.2722e-04, 1.1098e-03, 1.8809e-02, 1.8207e-03, 3.9244e-04,\n",
      "         3.2941e-02, 3.4431e-04, 3.5727e-04],\n",
      "        [1.2143e-01, 6.9474e-04, 1.3977e-03, 5.5937e-03, 2.0280e-03, 1.7718e-03,\n",
      "         1.3170e-01, 9.6083e-04, 1.2649e-03, 3.5961e-01, 8.6518e-04, 7.1996e-04,\n",
      "         2.1349e-03, 3.4875e-03, 7.0238e-04, 2.5422e-01, 7.1540e-04, 1.1214e-03,\n",
      "         4.4794e-02, 9.3779e-04, 1.5791e-03, 2.2555e-02, 2.4547e-03, 5.7389e-04,\n",
      "         3.5655e-02, 5.1975e-04, 5.2197e-04],\n",
      "        [1.2143e-01, 6.9474e-04, 1.3977e-03, 5.5937e-03, 2.0280e-03, 1.7718e-03,\n",
      "         1.3170e-01, 9.6083e-04, 1.2649e-03, 3.5961e-01, 8.6518e-04, 7.1996e-04,\n",
      "         2.1349e-03, 3.4875e-03, 7.0238e-04, 2.5422e-01, 7.1540e-04, 1.1214e-03,\n",
      "         4.4794e-02, 9.3779e-04, 1.5791e-03, 2.2555e-02, 2.4547e-03, 5.7389e-04,\n",
      "         3.5655e-02, 5.1975e-04, 5.2197e-04],\n",
      "        [1.2143e-01, 6.9474e-04, 1.3977e-03, 5.5937e-03, 2.0280e-03, 1.7718e-03,\n",
      "         1.3170e-01, 9.6083e-04, 1.2649e-03, 3.5961e-01, 8.6518e-04, 7.1996e-04,\n",
      "         2.1349e-03, 3.4875e-03, 7.0238e-04, 2.5422e-01, 7.1540e-04, 1.1214e-03,\n",
      "         4.4794e-02, 9.3779e-04, 1.5791e-03, 2.2555e-02, 2.4547e-03, 5.7389e-04,\n",
      "         3.5655e-02, 5.1975e-04, 5.2197e-04],\n",
      "        [1.1629e-01, 1.0645e-03, 2.1031e-03, 7.0952e-03, 3.1762e-03, 2.6476e-03,\n",
      "         1.0943e-01, 1.4390e-03, 1.9617e-03, 3.5196e-01, 1.4003e-03, 1.1145e-03,\n",
      "         3.1547e-03, 5.0060e-03, 1.1407e-03, 2.6316e-01, 1.1933e-03, 1.7630e-03,\n",
      "         4.9498e-02, 1.4657e-03, 2.2529e-03, 2.4279e-02, 3.3209e-03, 9.3810e-04,\n",
      "         4.1381e-02, 8.7803e-04, 8.7765e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m         learn_iters \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m N \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mclear_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode\u001b[39m\u001b[38;5;124m'\u001b[39m, i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore \u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m e\u001b[38;5;241m.\u001b[39mscore, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_steps\u001b[39m\u001b[38;5;124m'\u001b[39m, n_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_steps\u001b[39m\u001b[38;5;124m'\u001b[39m, learn_iters)\n\u001b[1;32m     35\u001b[0m score_history\u001b[38;5;241m.\u001b[39mappend(e\u001b[38;5;241m.\u001b[39mscore)\n",
      "File \u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.9/site-packages/IPython/core/display_functions.py:386\u001b[0m, in \u001b[0;36mclear_output\u001b[0;34m(wait)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minteractiveshell\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InteractiveShell\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m InteractiveShell\u001b[38;5;241m.\u001b[39minitialized():\n\u001b[0;32m--> 386\u001b[0m     \u001b[43mInteractiveShell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_pub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclear_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[2K\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.9/site-packages/ipykernel/zmqshell.py:146\u001b[0m, in \u001b[0;36mZMQDisplayPublisher.clear_output\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m\"\"\"Clear output associated with the current execution (cell).\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(wait\u001b[38;5;241m=\u001b[39mwait)\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush_streams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_socket,\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclear_output\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m     ident\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic,\n\u001b[1;32m    153\u001b[0m )\n",
      "File \u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.9/site-packages/ipykernel/zmqshell.py:65\u001b[0m, in \u001b[0;36mZMQDisplayPublisher._flush_streams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flush_streams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124;03m\"\"\"flush IO Streams prior to display\"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.9/site-packages/ipykernel/iostream.py:480\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "e = Environment((3,3,3),negreward=-5)\n",
    "\n",
    "N = 10\n",
    "batch_size = 32\n",
    "n_epochs = 4\n",
    "alpha = 0.0003\n",
    "\n",
    "\n",
    "agent = Agent(n_actions=e.action_space, batch_size=batch_size, \n",
    "                alpha=alpha, n_epochs=n_epochs, \n",
    "                input_dims=e.observation_space)\n",
    "\n",
    "n_games = 5000\n",
    "\n",
    "score_history = []\n",
    "\n",
    "n_steps = 0\n",
    "learn_iters = 0\n",
    "for i in range(n_games):\n",
    "    e.resetEnvironment()\n",
    "    while not e.done:\n",
    "        action, prob, val = agent.choose_action(e.genObs())\n",
    "        #print(action, prob, val)\n",
    "        oldState, newState, action, reward, done = e.step(action)\n",
    "        n_steps += 1\n",
    "        agent.remember(oldState, action, prob, val, reward, done)\n",
    "        \n",
    "        if n_steps % N == 0:\n",
    "            agent.learn()\n",
    "            learn_iters += 1\n",
    "    if i % N == 0:\n",
    "        clear_output(wait=True)\n",
    "        print('episode', i, 'score %.1f' % e.score, 'time_steps', n_steps, 'learning_steps', learn_iters)\n",
    "    score_history.append(e.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143d7358",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(score_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85825580",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.environment.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7168bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81896f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
